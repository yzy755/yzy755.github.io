[{"title":"spring-cloud 手脚架搭建遇到的坑","date":"2020-11-23T02:49:05.000Z","path":"2020/11/23/spring-cloud-手脚架搭建遇到的坑/","text":"新技术总是能遇到各种各样的坑 openfeign的坑 因为spring-cloud调用服务是基于http协议的，所有需要定义没个接口的url，然后前端调用我们的web服务有需要一套url，如果定义两套url就显得非常麻烦，按照以前的习惯，接到需求后后台进行模块拆分，比如商品模块，订单模块，拆分后对应到代码就是controller的拆分，定义好controller和所有接口的url、入参、出参，开始编写接口文档…使用spring-cloud之后也希望能这样，所有对每个模块抽象出一个共用的api 调用示例： 封装接口 123456789@RequestMapping(\"/api/user\")public interface UserApi &#123; @RequestMapping(value = &#123; \"/getbyid\" &#125;, method = &#123; RequestMethod.GET &#125;) ApiResult&lt;UserVo&gt; getUserById(); @RequestMapping(value = &#123; \"/saveuser\" &#125;, method = &#123; RequestMethod.POST &#125;) ApiResult&lt;Boolean&gt; saveUser(@RequestBody ApiParam&lt;UserVo&gt; param);&#125; 然后多了一步就是定义一个FeignClient接口来继承我们封装的api接口 1234@FeignClient(\"hwuser-center\")public interface UserFacade extends UserApi &#123;&#125; 然后service中定义controller对外提供服务 1234567891011121314151617181920212223@RestControllerpublic class UserController implements UserApi &#123; private static final Logger logger = LoggerFactory.getLogger(UserController.class); @Override public ApiResult&lt;UserVo&gt; getUserById() &#123; return ApiResult.success(new UserVo()); &#125; @Override public ApiResult&lt;Boolean&gt; saveUser(ApiParam&lt;UserVo&gt; param) &#123; return new ApiResult(true); &#125; public ApiResult&lt;PageInfo&lt;UserVo&gt;&gt; saveUser11(ApiParam&lt;UserVo&gt; param) &#123; return new ApiResult(true); &#125;&#125; 最后就是controller来实现我们封装的api接口 12345678910111213141516171819202122232425@RestControllerpublic class UserBizController implements UserApi &#123; private static final Logger LOG = LoggerFactory.getLogger(UserBizController.class); @Resource UserFacade userFacade; @Override public ApiResult getById(HttpServletRequest request, HttpServletResponse response, Long id) throws Exception &#123; try &#123; LOG.info(\"enter\"); UserVo vo = new UserVo(); vo.setId(id); ApiParam&lt;UserVo&gt; apiParam = ApiParam.newApiParam(vo, new HcContext()); ApiResult&lt;UserVo&gt; apiResult = userFacade.getUserById(); return apiResult; &#125; catch (Exception e) &#123; LOG.error(\"getById异常：&#123;&#125;\", e.getMessage(), e); return new ApiResult(-1, e.getMessage()); &#125; &#125;&#125; 感觉大功告成，但是一启动报错了 12345Caused by: java.lang.IllegalStateException: Ambiguous mapping. Cannot map 'com.gzhc365.hw.user.facade.UserFacade' method public abstract com.gzhc365.cloud.commons.api.ApiResult&lt;com.gzhc365.hw.user.vo.UserVo&gt; com.gzhc365.hw.user.api.UserApi.getUserById()to &#123;[/api/user/getbyid],methods=[GET]&#125;: There is already 'userController' bean methodpublic com.gzhc365.cloud.commons.api.ApiResult&lt;com.gzhc365.hw.user.vo.UserVo&gt; com.gzhc365.hw.user.web.controller.UserController.getUserById() mapped. at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry.assertUniqueMethodMapping(AbstractHandlerMethodMapping.java:581) 这里我让@RequestMapping(“/api/user”)直接修饰userApi接口，用来暴露出去统一前缀，然后FeignClient继承了这个Mapping，spring加载会动态代理出FeignClient的实现类来模拟userApi中定义的mapping，然后我们的service中对外暴露的controller也实现了userApi，所有spring加载了两套一模一样url的mapping就报错了。解决的办法就是将userApi接口上的@RequestMapping(“/api/user”)去掉，将完整的url写在每个接口上，但是这样有个问题就是没法给暴露出去的api做统一前缀了。","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://yzy755.github.io/tags/spring-cloud/"}]},{"title":"spring-cloud 手脚架搭建","date":"2020-11-20T03:48:05.000Z","path":"2020/11/20/spring-cloud-手脚架搭建/","text":"公司一直都是dubbo架构微服务，在外面如火如荼的spring-cloud技术面前显得有些落后，所以决定慢慢将团队的架构往spring-cloud架构迁移，那手脚架必不可少。 dubbo架构的项目图如下： 每个模块都会拆分为两个module，取名hc-facade-xxx、hc-service-xxx， facade中存放DTO,VO,enum等对外依赖的类，最重要的是存放dubbo对外暴露的facade接口 service中主要是放数据库entity，dao，service，facade实现，所有的配置文件包括dubbo生产者消费者配置，spring，数据库等都会放在service中 简单的项目依赖如下： 搭建手脚架也同样采用相同的项目结构和依赖关系，项目图如下： spring-cloud(Finchley.SR2) 使用以下组件 注册中心：Eureka 配置中心：Apollo 接口调用：OpenFeign 网关：zuul 注册中心用的是公司选择的Eureka而非alibaba的nacos，有点遗憾，不过大同小异了，使用上差不多，nacos多了配置中心的功能，而配置中心沿用了之前的技术选型Apollo，配置的转移工作量大，左右没有上config，OpenFeign 是为了调用service接口尽量像dubbo一样调用本地方法一样 搭建注册中心服务端 引入pom依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka- server&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件 12345678910111213eureka: server: # eureka缓存，true开启缓存，false关闭，生产环境建议为true enable-self-preservation: true client: register-with-eureka: false # 是否注册中心注册自己 true为是，可以在注册中心列表找到自己 service-url: # Eureka客户端与Eureka服务端进行交互的地址 defaultZone: http://localhost:$&#123;server.port&#125;/eureka/ # 是否从Eureka中获取服务信息 fetch-registry: false # 多个注册中心集群 # defaultZone: http://localhost:8761/eureka/,http://localhost:8080/eureka/ 启动类添加注解 123456789@EnableDiscoveryClient@SpringBootApplicationpublic class UserServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UserServiceApplication.class, args); &#125;&#125; 搭建注册中心客户端 12345&lt;!-- eureka依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件 123eureka.client.service-url.defaultZone=http://localhost:8088/eureka/eureka.instance.prefer-ip-address=trueeureka.instance.instance-id = $&#123;spring.cloud.client.ip-address&#125;:$&#123;server.port&#125; 启动类添加注解 1234567@SpringBootApplication@EnableEurekaClientpublic class Product1Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Product1Application.class, args); &#125;&#125; openfeign搭建 12345&lt;!-- feign依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 调用示例 封装接口 12345678public interface UserApi &#123; @RequestMapping(value = &#123; \"/api/user/getbyid\" &#125;, method = &#123; RequestMethod.GET &#125;) ApiResult&lt;UserVo&gt; getUserById(); @RequestMapping(value = &#123; \"/api/user/saveuser\" &#125;, method = &#123; RequestMethod.POST &#125;) ApiResult&lt;Boolean&gt; saveUser(@RequestBody ApiParam&lt;UserVo&gt; param);&#125; FeignClient接口 1234@FeignClient(\"hwuser-center\")public interface UserFacade extends UserApi &#123;&#125; service中的业务实现controller 1234567891011121314151617181920212223@RestControllerpublic class UserController implements UserApi &#123; private static final Logger logger = LoggerFactory.getLogger(UserController.class); @Override public ApiResult&lt;UserVo&gt; getUserById() &#123; return ApiResult.success(new UserVo()); &#125; @Override public ApiResult&lt;Boolean&gt; saveUser(ApiParam&lt;UserVo&gt; param) &#123; return new ApiResult(true); &#125; public ApiResult&lt;PageInfo&lt;UserVo&gt;&gt; saveUser11(ApiParam&lt;UserVo&gt; param) &#123; return new ApiResult(true); &#125;&#125; web controller 12345678910111213141516171819202122232425@RestControllerpublic class UserBizController implements UserApi &#123; private static final Logger LOG = LoggerFactory.getLogger(UserBizController.class); @Resource UserFacade userFacade; @Override public ApiResult getById(HttpServletRequest request, HttpServletResponse response, Long id) throws Exception &#123; try &#123; LOG.info(\"enter\"); UserVo vo = new UserVo(); vo.setId(id); ApiParam&lt;UserVo&gt; apiParam = ApiParam.newApiParam(vo, new HcContext()); ApiResult&lt;UserVo&gt; apiResult = userFacade.getUserById(); return apiResult; &#125; catch (Exception e) &#123; LOG.error(\"getById异常：&#123;&#125;\", e.getMessage(), e); return new ApiResult(-1, e.getMessage()); &#125; &#125;&#125;","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://yzy755.github.io/tags/spring-cloud/"}]},{"title":"docker学习笔记","date":"2020-09-22T12:48:05.000Z","path":"2020/09/22/docker学习笔记/","text":"[toc] docker是什么docker的思想来自于集装箱，将各式各样的服务打包装箱，集装箱与集装箱之间相互隔离，互不影响，这样的话这种不同的服务就都能在一艘船上打包运走而不需要正对不同的集装箱（服务）用不同的船（pc机）运走了，是一种容器化技术。 docker为什么出现传统的服务部署一般都在虚拟机上，代表有VMware、OpenStack等，在各个虚拟机上需要各自安装服务，如果集群规模很大的话需要重复部署N套环境，而且环境复杂切容易出现不一致的情况，即便是使用镜像也需要不断的备份和分发，运维工作十分痛苦。 docker也是虚拟化技术，属于轻量级的虚拟化，也叫容器化技术，docker不需要整套的操作系统环境，只需要必要的小规模环境，相遇虚拟机动辄几G十几G，docker镜像甚至只要M级别。docker对内存的利用率极高，因为他不需要想虚拟机一样固定分配一定的内存，docker就像是电脑上的一个进程，需要多少就分配多少。 总结一下docker与虚拟机的不同 传统虚拟机，虚拟出一条硬件，运行一个完整的操作系统，然后在这个系统上安装和运行软件 容器内的应用直接运行在宿主机的内容，容器是没有自己的内核的，也没有虚拟我们的硬件，所以就轻便了 每个容器间是互相隔离，每个容器内都有一个属于自己的文件系统，互不影响 docker的构成镜像（image）： 镜像好比java中类，java通过类来创建实例，docker通过镜像来创建一个或多个容器服务。 容器（container）: 利用容器独立运行一个或一组应用，是用过镜像来创建的。 仓库（repository）： 仓库是存放镜像的地方，需要什么环境的镜像就从仓库中直接拿，跟git类似分为公有仓库和私有仓库，docker hub、阿里云都有镜像服务器。 docker的使用docker安装12345678910111213141516171819202122232425262728293031323334353637383940414243#1.卸载旧版本yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine#2.需要的安装包yum install -y yum-utils#3.设置镜像的仓库yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo#上述方法默认是从国外的，不推荐#推荐使用国内的yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo #更新yum软件包索引yum makecache fast#4.安装docker相关的 docker-ce 社区版 而ee是企业版yum install docker-ce docker-ce-cli containerd.io # 这里我们使用社区版即可#5.启动dockersystemctl start docker#6. 使用docker version查看是否按照成功docker version#7. 测试docker run hello-world12345678910111213141516171819202122232425262728293031323334353637#8.查看已经下载的镜像(从这里可以查看已有镜像的id)[root@iz2zeak7sgj6i7hrb2g862z ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest bf756fb1ae65 4 months ago 13.3kB1234 docker卸载1234#1. 卸载依赖yum remove docker-ce docker-ce-cli containerd.io#2. 删除资源rm -rf /var/lib/docker docker常用命令1234567891011121314151617181920212223242526272829303132333435363738394041attach Attach local standard input, output, and error streams to a running container #当前shell下 attach连接指定运行的镜像 build Build an image from a Dockerfile # 通过Dockerfile定制镜像 commit Create a new image from a container&apos;s changes #提交当前容器为新的镜像 cp Copy files/folders between a container and the local filesystem #拷贝文件 create Create a new container #创建一个新的容器 diff Inspect changes to files or directories on a container&apos;s filesystem #查看docker容器的变化 events Get real time events from the server # 从服务获取容器实时时间 exec Run a command in a running container # 在运行中的容器上运行命令 export Export a container&apos;s filesystem as a tar archive #导出容器文件系统作为一个tar归档文件[对应import] history Show the history of an image # 展示一个镜像形成历史 images List images #列出系统当前的镜像 import Import the contents from a tarball to create a filesystem image #从tar包中导入内容创建一个文件系统镜像 info Display system-wide information # 显示全系统信息 inspect Return low-level information on Docker objects #查看容器详细信息 kill Kill one or more running containers # kill指定docker容器 load Load an image from a tar archive or STDIN #从一个tar包或标准输入中加载一个镜像[对应save] login Log in to a Docker registry # 注册或登录一个 docker 源服务器 logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codes docker加载原理 联合文件系统 docker的镜像都是由一层一层的文件系统组成，docker利用文件版本管理来实现分层的复用，比如说镜像1依赖了centos层，docker下载完镜像1会在系统中记录centos的分层，镜像2页依赖了centos层，下载镜像2则不会再重复下载centos层，而是直接复用，简单来说每一层都是一条记录。 加载原理分析 平时用到的操作系统是基于 boot file system（bootfs），系统启动需要引导加载，加载内核，之后计算机内存的使用权由boot file system 转交给内核（kernel），boot file system 则被操作系统卸载，这个过程很慢，通常是分钟级别的，这个引导加载器是通用的。 root file system（rootfs），在bootfs之上，对应的操作系统不同的发行版，比如linux系统的centos、ubuntu。 虚拟机技术需要模拟这两种文件系统进行加载，所以系统很慢，而且体积庞大，而docker使用宿主机的内核，无需引导加载（无需boot file system），只需要提供root file system，可以自由精简命令和工具包，所以速度非常快，体积要小很多。","tags":[{"name":"docker","slug":"docker","permalink":"http://yzy755.github.io/tags/docker/"}]},{"title":"spring-cloud-alibaba操作手册之分布式事务","date":"2020-03-07T08:55:54.000Z","path":"2020/03/07/spring-cloud-alibaba操作手册之分布式事务/","text":"分布式事务模拟分布式事务异常1、创建两个工程 order、pay，pom.xml 12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 2、建两个数据库 order、pay，两个微服务分别访问。 3、分别写两个服务的 application.yml 12345678910server: port: 8010spring: application: name: order datasource: driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 url: jdbc:mysql://localhost:3306/order 12345678910server: port: 8020spring: application: name: pay datasource: driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 url: jdbc:mysql://localhost:3306/pay 4、分别写两个 Service 123456789101112131415package com.southwind.service;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.stereotype.Service;@Servicepublic class OrderService &#123; @Autowired private JdbcTemplate jdbcTemplate; public void save()&#123; this.jdbcTemplate.update(\"insert into orders(username) values ('张三')\"); &#125;&#125; 123456789101112131415package com.southwind.service;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.stereotype.Service;@Servicepublic class PayService &#123; @Autowired private JdbcTemplate jdbcTemplate; public void save()&#123; this.jdbcTemplate.update(\"insert into pay(username) values ('张三')\"); &#125;&#125; 5、控制器 Order 通过 RestTemplate 调用 Pay 的服务 1234567891011121314151617181920212223242526package com.southwind.controller;import com.southwind.service.OrderService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestControllerpublic class OrderController &#123; @Autowired private OrderService orderService; @Autowired private RestTemplate restTemplate; @GetMapping(\"/save\") public String save()&#123; //订单 this.orderService.save(); int i = 10/0; //支付 this.restTemplate.getForObject(\"http://localhost:8020/save\",String.class); return \"success\"; &#125;&#125; 123456789101112131415161718package com.southwind.controller;import com.southwind.service.PayService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class PayController &#123; @Autowired private PayService payService; @GetMapping(\"/save\") public String save()&#123; this.payService.save(); return \"success\"; &#125;&#125; 6、启动类 12345678910111213141516171819package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class OrderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderApplication.class, args); &#125; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 12345678910111213package com.southwind;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class PayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(PayApplication.class, args); &#125;&#125; 分布式异常模拟结束，Order 存储完成之后，出现异常，会导致 Pay 无法存储，但是 Order 数据库不会进行回滚。 Seata 解决1、下载 2、解压，修改两个文件 regisry.conf 1234567891011121314151617registry &#123; type = &quot;nacos&quot; nacos &#123; serverAddr = &quot;localhost&quot; namespace = &quot;public&quot; cluster = &quot;default&quot; &#125;&#125;config &#123; type = &quot;nacos&quot; nacos &#123; serverAddr = &quot;localhost&quot; namespace = &quot;public&quot; cluster = &quot;default&quot; &#125;&#125; nacos-config.txt 3、启动 Nacos，运行 nacos-config.sh 将 Seata 配置导入 Nacos 进入 conf，右键 Git Bash Here 12cd confsh nacos-config.sh 127.0.0.1 执行成功，刷新 Nacos，配置加入 nacos-config.txt 配置已生效 4、启动 Seata Server， JDK 8 以上环境无法启动 12cd binseata-server.bat -p 8090 -m file 启动成功，Nacos 注册成功。 Seata 服务环境搭建完毕，接下来去应用中添加。 1、初始化数据库，在两个数据库中添加事务日志记录表，SQL Seata 已经提供。 2、直接在两个数据库运行脚本。 12345678910111213CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `context` varchar(128) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, `ext` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 3、两个工程的 pom.xml 添加 Seata 组件和 Nacos Config 组件。 12345678910&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 4、给 JDBCTemplate 添加代理数据源 12345678910111213141516171819202122232425262728package com.southwind;import io.seata.rm.datasource.DataSourceProxy;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.web.client.RestTemplate;import javax.sql.DataSource;@SpringBootApplicationpublic class OrderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderApplication.class, args); &#125; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125; @Bean public JdbcTemplate jdbcTemplate(DataSource dataSource)&#123; return new JdbcTemplate(new DataSourceProxy(dataSource)); &#125;&#125; 1234567891011121314151617181920212223package com.southwind;import io.seata.rm.datasource.DataSourceProxy;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.jdbc.core.JdbcTemplate;import javax.sql.DataSource;@SpringBootApplicationpublic class PayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(PayApplication.class, args); &#125; @Bean public JdbcTemplate jdbcTemplate(DataSource dataSource)&#123; return new JdbcTemplate(new DataSourceProxy(dataSource)); &#125;&#125; 5、将 registry.conf 复制到两个工程的 resources 下。 6、给两个工程添加 bootstrap.yml 读取 Nacos 配置。 123456789101112spring: application: name: order cloud: nacos: config: server-addr: localhost:8848 namespace: public group: SEATA_GROUP alibaba: seata: tx-service-group: $&#123;spring.application.name&#125; 123456789101112spring: application: name: pay cloud: nacos: config: server-addr: localhost:8848 namespace: public group: SEATA_GROUP alibaba: seata: tx-service-group: $&#123;spring.application.name&#125; tx-service-group 需要和 Nacos 配置中的名称一致。 7、在 Order 调用 Pay 处添加注解 @GlobalTransactional 12345678910111213141516171819202122232425262728package com.southwind.controller;import com.southwind.service.OrderService;import io.seata.spring.annotation.GlobalTransactional;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestControllerpublic class OrderController &#123; @Autowired private OrderService orderService; @Autowired private RestTemplate restTemplate; @GetMapping(\"/save\") @GlobalTransactional public String save()&#123; //订单 this.orderService.save(); int i = 10/0; //支付 this.restTemplate.getForObject(\"http://localhost:8020/save\",String.class); return \"success\"; &#125;&#125;","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://yzy755.github.io/tags/spring-cloud/"}]},{"title":"spring-cloud-alibaba操作手册之服务网关","date":"2020-03-06T03:17:22.000Z","path":"2020/03/06/spring-cloud-alibaba操作手册之服务网关/","text":"服务网关Spring Cloud Gateway 是基于 Netty，跟 Servlet 不兼容，所以你的工程中不能出现 Servlet 的组件 。 1、pom.xml 注意，一定不能出现 spring web 的依赖，因为 Gateway 与 Servlet 不兼容。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt; 2、application.yml 1234567891011121314151617server: port: 8010spring: application: name: gateway cloud: gateway: discovery: locator: enabled: true routes: - id: provider_route uri: http://localhost:8081 predicates: - Path=/provider/** filters: - StripPrefix=1 上面这种做法其实没有用到 nacos ，现在我们让 gateway 直接去 nacos 中发现服务，配置更加简单了。 1、pom.xml 引入 nacos 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 2、application.yml 12345678910server: port: 8010spring: application: name: gateway cloud: gateway: discovery: locator: enabled: true Gateway 限流基于路由限流 1、pom.xml 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-spring-cloud-gateway-adapter&lt;/artifactId&gt;&lt;/dependency&gt; 2、配置类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package com.southwind.configuration;import com.alibaba.csp.sentinel.adapter.gateway.common.rule.GatewayFlowRule;import com.alibaba.csp.sentinel.adapter.gateway.common.rule.GatewayRuleManager;import com.alibaba.csp.sentinel.adapter.gateway.sc.SentinelGatewayFilter;import com.alibaba.csp.sentinel.adapter.gateway.sc.callback.BlockRequestHandler;import com.alibaba.csp.sentinel.adapter.gateway.sc.callback.GatewayCallbackManager;import com.alibaba.csp.sentinel.adapter.gateway.sc.exception.SentinelGatewayBlockExceptionHandler;import org.springframework.beans.factory.ObjectProvider;import org.springframework.cloud.gateway.filter.GlobalFilter;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.Ordered;import org.springframework.core.annotation.Order;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.http.codec.ServerCodecConfigurer;import org.springframework.web.reactive.function.BodyInserters;import org.springframework.web.reactive.function.server.ServerResponse;import org.springframework.web.reactive.result.view.ViewResolver;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;import javax.annotation.PostConstruct;import java.util.*;@Configurationpublic class GatewayConfiguration &#123; private final List&lt;ViewResolver&gt; viewResolvers; private final ServerCodecConfigurer serverCodecConfigurer; public GatewayConfiguration(ObjectProvider&lt;List&lt;ViewResolver&gt;&gt; viewResolversProvider, ServerCodecConfigurer serverCodecConfigurer) &#123; this.viewResolvers = viewResolversProvider.getIfAvailable(Collections::emptyList); this.serverCodecConfigurer = serverCodecConfigurer; &#125; //配置限流的异常处理 @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public SentinelGatewayBlockExceptionHandler sentinelGatewayBlockExceptionHandler() &#123; return new SentinelGatewayBlockExceptionHandler(viewResolvers, serverCodecConfigurer); &#125; //配置初始化的限流参数 @PostConstruct public void initGatewayRules()&#123; Set&lt;GatewayFlowRule&gt; rules = new HashSet&lt;&gt;(); rules.add( new GatewayFlowRule(\"provider_route\") .setCount(1) .setIntervalSec(1) ); GatewayRuleManager.loadRules(rules); &#125; //初始化限流过滤器 @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public GlobalFilter sentinelGatewayFilter() &#123; return new SentinelGatewayFilter(); &#125; //自定义限流异常页面 @PostConstruct public void initBlockHandlers()&#123; BlockRequestHandler blockRequestHandler = new BlockRequestHandler() &#123; @Override public Mono&lt;ServerResponse&gt; handleRequest(ServerWebExchange serverWebExchange, Throwable throwable) &#123; Map map = new HashMap(); map.put(\"code\",0); map.put(\"msg\",\"被限流了\"); return ServerResponse.status(HttpStatus.OK) .contentType(MediaType.APPLICATION_JSON) .body(BodyInserters.fromObject(map)); &#125; &#125;; GatewayCallbackManager.setBlockHandler(blockRequestHandler); &#125;&#125; 3、application.yml 1234567891011121314151617server: port: 8010spring: application: name: gateway cloud: gateway: discovery: locator: enabled: true routes: - id: provider_route uri: http://localhost:8081 predicates: - Path=/provider/** filters: - StripPrefix=1 基于 API 分组限流 1、修改配置类，添加基于 API 分组限流的方法，修改初始化的限流参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102package com.southwind.configuration;import com.alibaba.csp.sentinel.adapter.gateway.common.SentinelGatewayConstants;import com.alibaba.csp.sentinel.adapter.gateway.common.api.ApiDefinition;import com.alibaba.csp.sentinel.adapter.gateway.common.api.ApiPathPredicateItem;import com.alibaba.csp.sentinel.adapter.gateway.common.api.ApiPredicateItem;import com.alibaba.csp.sentinel.adapter.gateway.common.api.GatewayApiDefinitionManager;import com.alibaba.csp.sentinel.adapter.gateway.common.rule.GatewayFlowRule;import com.alibaba.csp.sentinel.adapter.gateway.common.rule.GatewayRuleManager;import com.alibaba.csp.sentinel.adapter.gateway.sc.SentinelGatewayFilter;import com.alibaba.csp.sentinel.adapter.gateway.sc.callback.BlockRequestHandler;import com.alibaba.csp.sentinel.adapter.gateway.sc.callback.GatewayCallbackManager;import com.alibaba.csp.sentinel.adapter.gateway.sc.exception.SentinelGatewayBlockExceptionHandler;import org.springframework.beans.factory.ObjectProvider;import org.springframework.cloud.gateway.filter.GlobalFilter;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.Ordered;import org.springframework.core.annotation.Order;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.http.codec.ServerCodecConfigurer;import org.springframework.web.reactive.function.BodyInserters;import org.springframework.web.reactive.function.server.ServerResponse;import org.springframework.web.reactive.result.view.ViewResolver;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;import javax.annotation.PostConstruct;import java.util.*;@Configurationpublic class GatewayConfiguration &#123; private final List&lt;ViewResolver&gt; viewResolvers; private final ServerCodecConfigurer serverCodecConfigurer; public GatewayConfiguration(ObjectProvider&lt;List&lt;ViewResolver&gt;&gt; viewResolversProvider, ServerCodecConfigurer serverCodecConfigurer) &#123; this.viewResolvers = viewResolversProvider.getIfAvailable(Collections::emptyList); this.serverCodecConfigurer = serverCodecConfigurer; &#125; //配置限流的异常处理 @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public SentinelGatewayBlockExceptionHandler sentinelGatewayBlockExceptionHandler() &#123; return new SentinelGatewayBlockExceptionHandler(viewResolvers, serverCodecConfigurer); &#125; //配置初始化的限流参数 @PostConstruct public void initGatewayRules()&#123; Set&lt;GatewayFlowRule&gt; rules = new HashSet&lt;&gt;(); rules.add(new GatewayFlowRule(\"provider_api1\").setCount(1).setIntervalSec(1)); rules.add(new GatewayFlowRule(\"provider_api2\").setCount(1).setIntervalSec(1)); GatewayRuleManager.loadRules(rules); &#125; //初始化限流过滤器 @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public GlobalFilter sentinelGatewayFilter() &#123; return new SentinelGatewayFilter(); &#125; //自定义限流异常页面 @PostConstruct public void initBlockHandlers()&#123; BlockRequestHandler blockRequestHandler = new BlockRequestHandler() &#123; @Override public Mono&lt;ServerResponse&gt; handleRequest(ServerWebExchange serverWebExchange, Throwable throwable) &#123; Map map = new HashMap(); map.put(\"code\",0); map.put(\"msg\",\"被限流了\"); return ServerResponse.status(HttpStatus.OK) .contentType(MediaType.APPLICATION_JSON) .body(BodyInserters.fromObject(map)); &#125; &#125;; GatewayCallbackManager.setBlockHandler(blockRequestHandler); &#125; //自定义API分组 @PostConstruct private void initCustomizedApis()&#123; Set&lt;ApiDefinition&gt; definitions = new HashSet&lt;&gt;(); ApiDefinition api1 = new ApiDefinition(\"provider_api1\") .setPredicateItems(new HashSet&lt;ApiPredicateItem&gt;()&#123;&#123; add(new ApiPathPredicateItem().setPattern(\"/provider/api1/**\") .setMatchStrategy(SentinelGatewayConstants.URL_MATCH_STRATEGY_PREFIX)); &#125;&#125;); ApiDefinition api2 = new ApiDefinition(\"provider_api2\") .setPredicateItems(new HashSet&lt;ApiPredicateItem&gt;()&#123;&#123; add(new ApiPathPredicateItem().setPattern(\"/provider/api2/demo1\")); &#125;&#125;); definitions.add(api1); definitions.add(api2); GatewayApiDefinitionManager.loadApiDefinitions(definitions); &#125;&#125; 2、Controller 添加方法 12345678910111213141516171819@GetMapping(\"/api1/demo1\")public String demo1()&#123; return \"demo\";&#125;@GetMapping(\"/api1/demo2\")public String demo2()&#123; return \"demo\";&#125;@GetMapping(\"/api2/demo1\")public String demo3()&#123; return \"demo\";&#125;@GetMapping(\"/api2/demo2\")public String demo4()&#123; return \"demo\";&#125; 也可以基于 Nacos 服务发现组件进行限流 12345678910server: port: 8010spring: application: name: gateway cloud: gateway: discovery: locator: enabled: true API 分组代码修改，改为 discovery 中的服务名。 1234ApiDefinition api2 = new ApiDefinition(\"provider_api2\") .setPredicateItems(new HashSet&lt;ApiPredicateItem&gt;()&#123;&#123; add(new ApiPathPredicateItem().setPattern(\"/p1/api2/demo1\")); &#125;&#125;);","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://yzy755.github.io/tags/spring-cloud/"}]},{"title":"spring-cloud-alibaba操作手册之整合 RocketMQ","date":"2020-03-05T09:23:40.000Z","path":"2020/03/05/spring-cloud-alibaba操作手册之整合 RocketMQ/","text":"整合 RocketMQ安装 RocketMQ1、传入 Linux 服务器 2、解压缩 1unzip rocketmq-all-4.7.1-bin-release.zip 3、启动 NameServer 1nohup ./bin/mqnamesrv &amp; 4、检查是否启动成功 1netstat -an | grep 9876 5、启动 Broker 启动之前需要编辑配置文件，修改 JVM 内存设置，默认给的内存 4 GB，超过我们的 JVM 了。 12cd binvim runserver.sh 1vim runbroker.sh 启动 Broker 1nohup ./mqbroker -n localhost:9876 &amp; 可以查看日志 1tail -f ~/logs/rocketmqlogs/broker.log 启动成功 6、测试 RocketMQ 消息发送 123cd binexport NAMESRV_ADDR=localhost:9876./tools.sh org.apache.rocketmq.example.quickstart.Producer 消息接收 123cd binexport NAMESRV_ADDR=localhost:9876./tools.sh org.apache.rocketmq.example.quickstart.Consumer 7、关闭 RocketMQ 123cd bin./mqshutdown broker./mqshutdown namesrv 安装 RocketMQ 控制台1、解压缩，修改配置，打包 1mvn clean package -Dmaven.test.skip=true 2、进入 target 启动 jar 1java -jar rocketmq-console-ng-1.0.0.jar 打开浏览器访问 localhost:9877，如果报错 这是因为我们的 RocketMQ 安装在 Linux 中，控制台在 windows，Linux 需要开放端口才能访问，开放 10909 和 9876 端口 1234firewall-cmd --zone=public --add-port=10909/tcp --permanentfirewall-cmd --zone=public --add-port=9876/tcp --permanentsystemctl restart firewalld.servicefirewall-cmd --reload 重新启动控制台项目 Java 实现消息发送1、pom.xml 中引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 2、生产消息 1234567891011121314151617181920212223package com.southwind;import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.common.message.Message;public class Test &#123; public static void main(String[] args) throws Exception &#123; //创建消息生产者 DefaultMQProducer producer = new DefaultMQProducer(\"myproducer-group\"); //设置NameServer producer.setNamesrvAddr(\"192.168.248.129:9876\"); //启动生产者 producer.start(); //构建消息对象 Message message = new Message(\"myTopic\",\"myTag\",(\"Test MQ\").getBytes()); //发送消息 SendResult result = producer.send(message, 1000); System.out.println(result); //关闭生产者 producer.shutdown(); &#125;&#125; 3、直接运行，如果报错 sendDefaultImpl call timeout，可以开放 10911 端口 123firewall-cmd --zone=public --add-port=10911/tcp --permanentsystemctl restart firewalld.servicefirewall-cmd --reload 打开 RocketMQ 控制台，可查看消息。 Java 实现消息消费123456789101112131415161718192021222324252627282930313233package com.southwind.service;import lombok.extern.slf4j.Slf4j;import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.client.exception.MQClientException;import org.apache.rocketmq.common.message.MessageExt;import java.util.List;@Slf4jpublic class ConsumerTest &#123; public static void main(String[] args) throws MQClientException &#123; //创建消息消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"myconsumer-group\"); //设置NameServer consumer.setNamesrvAddr(\"192.168.248.129:9876\"); //指定订阅的主题和标签 consumer.subscribe(\"myTopic\",\"*\"); //回调函数 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext) &#123; log.info(\"Message=&gt;&#123;&#125;\",list); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); //启动消费者 consumer.start(); &#125;&#125; Spring Boot 整合 RocketMQ provider 1、pom.xml 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.7.0&lt;/version&gt;&lt;/dependency&gt; 2、application.yml 1234rocketmq: name-server: 192.168.248.129:9876 producer: group: myprovider 3、Order 123456789101112131415161718package com.southwind.entity;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.util.Date;@Data@AllArgsConstructor@NoArgsConstructorpublic class Order &#123; private Integer id; private String buyerName; private String buyerTel; private String address; private Date createDate;&#125; 4、Controller 123456789101112131415@Autowiredprivate RocketMQTemplate rocketMQTemplate;@GetMapping(\"/create\")public Order create()&#123; Order order = new Order( 1, \"张三\", \"123123\", \"软件园\", new Date() ); this.rocketMQTemplate.convertAndSend(\"myTopic\",order); return order;&#125; consumer 1、pom.xml 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.7.0&lt;/version&gt;&lt;/dependency&gt; 2、application.yml 12rocketmq: name-server: 192.168.248.129:9876 3、Service 123456789@Slf4j@Service@RocketMQMessageListener(consumerGroup = \"myConsumer\",topic = \"myTopic\")public class SmsService implements RocketMQListener&lt;Order&gt; &#123; @Override public void onMessage(Order order) &#123; log.info(\"新订单&#123;&#125;,发短信\",order); &#125;&#125;","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://yzy755.github.io/tags/spring-cloud/"}]},{"title":"spring-cloud-alibaba操作手册之Sentinel 服务限流降级","date":"2020-03-04T07:20:21.000Z","path":"2020/03/04/spring-cloud-alibaba操作手册之Sentinel 服务限流降级/","text":"Sentinel 服务限流降级雪崩效应：有A服务的不可用导致的B、C…服务不可用的现象 解决方案 1、设置线程超时 2、设置限流 3、熔断器 Sentinel、Hystrix 1、pom.xml 引入依赖 123456789&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 2、application 配置 12345678910management: endpoints: web: exposure: include: '*'spring: cloud: sentinel: transport: dashboard: localhost:8080 3、下载 Sentinel 控制台，解压，启动。 流控规则 直接限流 关联限流 链路限流 1、pom.xml 添加依赖 1234567891011&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-core&lt;/artifactId&gt; &lt;version&gt;1.7.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-web-servlet&lt;/artifactId&gt; &lt;version&gt;1.7.1&lt;/version&gt;&lt;/dependency&gt; 2、application.yml 12345spring: cloud: sentinel: filter: enabled: false 3、写配置类 1234567891011121314151617181920package com.southwind.configuration;import com.alibaba.csp.sentinel.adapter.servlet.CommonFilter;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class FilterConfiguration &#123; @Bean public FilterRegistrationBean registrationBean()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new CommonFilter()); registrationBean.addUrlPatterns(\"/*\"); registrationBean.addInitParameter(CommonFilter.WEB_CONTEXT_UNIFY,\"false\"); registrationBean.setName(\"sentinelFilter\"); return registrationBean; &#125;&#125; 4、Service 12345678@Servicepublic class HelloService &#123; @SentinelResource(\"test\") public void test()&#123; System.out.println(\"test\"); &#125;&#125; 5、Controller 1234567891011@GetMapping(\"/test1\")public String test1()&#123; this.helloService.test(); return \"test1\";&#125;@GetMapping(\"/test2\")public String test2()&#123; this.helloService.test(); return \"test2\";&#125; 流控效果 快速失败 直接抛出异常 Warm UP 给系统一个预热的时间，预热时间段内单机阈值较低，预热时间过后单机阈值增加，预热时间内当前的单机阈值是设置的阈值的三分之一，预热时间过后单机阈值恢复设置的值。 排队等待 当请求调用失败之后，不会立即抛出异常，等待下一次调用，时间范围是超时时间，在时间范围内如果能请求成功则不抛出异常，如果请求则抛出异常。 降级规则 RT 单个请求的响应时间超过阈值，则进入准降级状态，接下来 1 S 内连续 5 个请求响应时间均超过阈值，就进行降级，持续时间为时间窗口的值。 异常比例 每秒异常数量占通过量的比例大于阈值，就进行降级处理，持续时间为时间窗口的值。 异常数 1 分钟内的异常数超过阈值就进行降级处理，时间窗口的值要大于 60S，否则刚结束熔断又进入下一次熔断了。 热点规则热点规则是流控规则的更细粒度操作，可以具体到对某个热点参数的限流，设置限流之后，如果带着限流参数的请求量超过阈值，则进行限流，时间为统计窗口时长。 必须要添加 @SentinelResource，即对资源进行流控。 1234567@GetMapping(\"/hot\")@SentinelResource(\"hot\")public String hot( @RequestParam(value = \"num1\",required = false) Integer num1, @RequestParam(value = \"num2\",required = false) Integer num2)&#123; return num1+\"-\"+num2;&#125; 授权规则给指定的资源设置流控应用（追加参数），可以对流控应用进行访问权限的设置，具体就是添加白名单和黑名单。 如何给请求指定流控应用，通过实现 RequestOriginParser 接口来完成，代码如下所示。 1234567891011121314151617package com.southwind.configuration;import com.alibaba.csp.sentinel.adapter.servlet.callback.RequestOriginParser;import org.springframework.util.StringUtils;import javax.servlet.http.HttpServletRequest;public class RequestOriginParserDefinition implements RequestOriginParser &#123; @Override public String parseOrigin(HttpServletRequest httpServletRequest) &#123; String name = httpServletRequest.getParameter(\"name\"); if(StringUtils.isEmpty(name))&#123; throw new RuntimeException(\"name is null\"); &#125; return name; &#125;&#125; 要让 RequestOriginParserDefinition 生效，需要在配置类中进行配置。 123456789101112131415package com.southwind.configuration;import com.alibaba.csp.sentinel.adapter.servlet.callback.WebCallbackManager;import org.springframework.context.annotation.Configuration;import javax.annotation.PostConstruct;@Configurationpublic class SentinelConfiguration &#123; @PostConstruct public void init()&#123; WebCallbackManager.setRequestOriginParser(new RequestOriginParserDefinition()); &#125;&#125; 自定义规则异常返回创建异常处理类 123456789101112131415161718192021222324package com.southwind.handler;import com.alibaba.csp.sentinel.adapter.servlet.callback.UrlBlockHandler;import com.alibaba.csp.sentinel.slots.block.BlockException;import com.alibaba.csp.sentinel.slots.block.degrade.DegradeException;import com.alibaba.csp.sentinel.slots.block.flow.FlowException;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;public class ExceptionHandler implements UrlBlockHandler &#123; @Override public void blocked(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, BlockException e) throws IOException &#123; httpServletResponse.setContentType(\"text/html;charset=utf-8\"); String msg = null; if(e instanceof FlowException)&#123; msg = \"限流\"; &#125;else if(e instanceof DegradeException)&#123; msg = \"降级\"; &#125; httpServletResponse.getWriter().write(msg); &#125;&#125; 进行配置。 12345678@Configurationpublic class SentinelConfiguration &#123; @PostConstruct public void init()&#123; WebCallbackManager.setUrlBlockHandler(new ExceptionHandler()); &#125;&#125;","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://yzy755.github.io/tags/spring-cloud/"}]},{"title":"spring-cloud-alibaba操作手册之Ribbon 负载均衡","date":"2020-03-03T02:50:20.000Z","path":"2020/03/03/spring-cloud-alibaba操作手册之Ribbon 负载均衡/","text":"Ribbon 负载均衡12345678910@Configurationpublic class ConsumerConfig &#123; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 123456789101112@RestControllerpublic class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/index\") public String index()&#123; return \"consumer远程调用provier：\"+this.restTemplate.getForObject(\"http://provider/index\", String.class); &#125;&#125; 随机 12345server: port: 8180provider: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule Nacos 权重 1234567891011121314151617181920212223242526272829@Slf4jpublic class NacosWeightedRule extends AbstractLoadBalancerRule &#123; @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; @Override public void initWithNiwsConfig(IClientConfig iClientConfig) &#123; //读取配置文件 &#125; @Override public Server choose(Object o) &#123; ILoadBalancer loadBalancer = this.getLoadBalancer(); BaseLoadBalancer baseLoadBalancer = (BaseLoadBalancer) loadBalancer; //获取要请求的微服务名称 String name = baseLoadBalancer.getName(); //获取服务发现的相关API NamingService namingService = nacosDiscoveryProperties.namingServiceInstance(); try &#123; Instance instance = namingService.selectOneHealthyInstance(name); log.info(\"选择的实例是port=&#123;&#125;,instance=&#123;&#125;\",instance.getPort(),instance); return new NacosServer(instance); &#125; catch (NacosException e) &#123; e.printStackTrace(); return null; &#125; &#125;&#125; 12345server: port: 8180provider: ribbon: NFLoadBalancerRuleClassName: com.southwind.configuration.NacosWeightedRule","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://yzy755.github.io/tags/spring-cloud/"}]},{"title":"spring-cloud-alibaba操作手册之Nacos 服务发现与调用","date":"2020-03-03T02:50:20.000Z","path":"2020/03/03/spring-cloud-alibaba操作手册之Nacos 服务发现与调用/","text":"Nacos 服务发现与调用pom.xml 添加 discovery，完成服务发现。 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 通过 discoveryClient 发现注册到 nacos 中的 provider 服务。 12345678910111213@RestControllerpublic class ConsumerController &#123; @Autowired private DiscoveryClient discoveryClient; @GetMapping(\"/instances\") public List&lt;ServiceInstance&gt; instances()&#123; List&lt;ServiceInstance&gt; provider = discoveryClient.getInstances(\"provider\"); return provider; &#125;&#125; 123456789@Configurationpublic class ConsumerConfig &#123; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 1234567891011121314151617@RestControllerpublic class ConsumerController &#123; @Autowired private DiscoveryClient discoveryClient; @Autowired private RestTemplate restTemplate; @GetMapping(\"/index\") public String index()&#123; List&lt;ServiceInstance&gt; provider = discoveryClient.getInstances(\"provider\"); int index = ThreadLocalRandom.current().nextInt(provider.size()); String url = provider.get(index).getUri()+\"/index\"; return \"consumer随机远程调用provier：\"+this.restTemplate.getForObject(url, String.class); &#125;&#125;","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://yzy755.github.io/tags/spring-cloud/"}]},{"title":"spring-cloud-alibaba操作手册之Nacos 服务注册","date":"2020-03-03T02:17:20.000Z","path":"2020/03/03/spring-cloud-alibaba操作手册之Nacos 服务注册/","text":"Nacos 服务注册解压，启动服务。 Nacos 搭建成功，接下来注册服务。 在父工程路径下创建子工程，让子工程继承父工程的环境依赖，pom.xml 中添加 nacos 发现组件。 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; application.yml 中配置 12345678spring: cloud: nacos: discovery: # 指定nacos server地址 server-addr: localhost:8848 application: name: my-nacos","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://yzy755.github.io/tags/spring-cloud/"}]},{"title":"spring-cloud-alibaba操作手册之创建父工程","date":"2020-03-02T09:17:53.000Z","path":"2020/03/02/spring-cloud-alibaba操作手册之创建父工程/","text":"创建父工程Spring Cloud Alibaba 的环境在父工程中创建，微服务的各个组件作为子工程，继承父工程的环境。 Spring Boot —》Spring Cloud —》Spring Cloud Alibaba 毕业版本 pom.xml 中添加。 1234567891011121314151617181920&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- Spring Cloud Hoxton --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR3&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud Alibaba --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://yzy755.github.io/tags/spring-cloud/"}]},{"title":"JAVA内存模型","date":"2019-06-05T13:22:51.000Z","path":"2019/06/05/JAVA内存模型/","text":"JAVA内存模型 即 Java Memory Model 即 JMM，它定义了主存、工作内存抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存、CPU 指令优化等。JMM 体现在以下几个方面 * 原子性 - 保证指令不会受到线程上下文切换的影响 * 可见性 - 保证指令不会受 cpu 缓存的影响 * 有序性 - 保证指令不会受 cpu 指令并行优化的影响 既然JMM需要规范这个三个方面，那么势必在某些情况下我们的java程序会因为这个三个方便产生问题咯，什么情况下呢，就是多线程并发使用共享资源的时候，我们一步一步来说 原子性问题如果一个语句执行一个单独不可分割的指令，那么它是原子的。严格的原子操作排除了任何抢占的可能性，更方便的理解是这个值永远是最新的 一个或多个操作，要么全部执行且在执行过程中不被任何因素打断 在学线程并发执行临界区代码时就容易发生非原子性操作，比如i++操作，保证原子性可以用synchronized、Lock独占锁解决，也可使用cas无锁机制解决 可见性问题cpu缓存结构现在的cpu都是多核的（单核cpu不存在线程并发请求临界资源问题），而且运行速度非常块，然而我们的存储设备（内存，硬盘）得读取速度远远跟不上的运算速度，所有就有了多级缓存（还有寄存器也可以看作缓存） 结构如图： 不同线程在不同cpu核心上对临界资源进行读写就存在缓存一致性的问题，因为不同CPU核心上的线程如果缓存了同一份主存上的数据然后进行写操作，线程彼此之间是不可见的，最后更新主存值的时候就会不准确，解决这个问题的办法就是禁用CPU缓存，让线程每次都去主存上读写数据，java使用 volatile 关键字来确保变量的可见性，当然，使用synchronized关键字来修饰代码块也是可以保证的。 有序性问题JVM 会在不影响正确性的前提下，可以调整语句的执行顺序，来充分发挥CPU运算单元的效率，前提是要符合as-if-serial语义，操作与操作之间要符合 happens-before 规则 12345678as-if-serial语义：不管怎么重排序，单线程程序的执行结果不能被改变。编译器、处理器都必须遵守as-if-serial语义happens-before 反映在以下几种情况： 1、线程解锁 m 之前对变量的写，对于接下来对 m 加锁的其它线程对该变量的读可见 2、线程对 volatile 变量的写，对接下来其它线程对该变量的读可见 3、线程结束前对变量的写，对其它线程得知它结束后的读可见（比如其它线程调用 t1.isAlive() 或t1.join()等待它结束） 4、线程 t1 打断 t2（interrupt）前对变量的写，对于其他线程得知 t2 被打断后对变量的读可见（通过t2.interrupted 或 t2.isInterrupted） 5、具有传递性，如果 x hb-&gt; y 并且 y hb-&gt; z 那么有 x hb-&gt; z 在java中，使用volatile关键字修饰变量可以防止指令重排序来解决有序性问题。 volatile原理volatile 的底层是通过对变量增加内存屏障（Memory Fence），内存屏障包含两种：读屏障、写屏障，对 volatile 变量的写指令后会加入写屏障对 volatile 变量的读指令前会加入读屏障 如何保证可见性12读屏障：保证在该屏障之后，对共享变量的读取加载的是主存中的最新数据写屏障：保证在该屏障之前，对贡献变量的改动都同不到主存中去 可以理解为被volatile修饰的共享变量的读写跳过CPU缓存，直接操作主存，而且有意思的是在写屏障之前的非volatile修饰的共享变量也能保证可见性 如何保证有序性12* 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后* 读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前 为什么不能保证原子性最重要的一点就是不能解决指令交错12* 写屏障仅仅是保证之后的读能够读到最新的结果，但不能保证多线程下读跑到它前面去* 而有序性的保证也只是保证了本线程内相关代码不被重排序","tags":[{"name":"JMM","slug":"JMM","permalink":"http://yzy755.github.io/tags/JMM/"}]},{"title":"JAVA内存结构","date":"2019-05-02T12:17:53.000Z","path":"2019/05/02/JAVA内存结构/","text":"程序计数器 虚拟机栈 本地方法栈 堆 方法区 直接内存（jdk1.8后） 程序计数器 Program Counter Register 程序计数器（寄存器） 作用，是记住下一条jvm指令的执行地址 特点 是线程私有的 不会存在内存溢出 虚拟机栈 Java Virtual Machine Stacks （Java 虚拟机栈） 每个线程运行时所需要的内存，没个栈由多个栈帧组成，对应着当前正在执行的那个方法，存储的是局部变量表、返回地址、操作数栈 本地方法栈 native 关键字修饰的方法分配的栈内存 堆 Heap 堆 通过new关键字创建的对象使用堆内存 线程共享，队中的对象需要考虑线程安全的问题 有专门的垃圾回收机制 构成 Eden区 survivor区 老年代 堆内存诊断 jps 工具查看当前系统中有哪些 java 进程 jmap 工具查看堆内存占用情况 jmap - heap 进程id jconsole 工具图形界面的，多功能的监测工具，可以连续监测 方法区 在jdk1.6及以前，方法区在堆内存中一个叫永久代的区域，属于堆内存 在jdk1.8中，从堆内存中移除了永久代，取而代之的是一个叫元空间的内存，元空间存放在物理内存中，不受jvm管理 这里不是简单地将整个永久代移除到元空间，原来常量池中字符串池（stringtable）依然保留在堆内存，对比如下 直接内存 Direct Memory 常见于 NIO 操作时，用于数据缓冲区 分配回收成本较高，但读写性能高 不受 JVM 内存回收管理 分配和回收 使用了 Unsafe 对象完成直接内存的分配回收，并且回收需要主动调用 freeMemory 方法 ByteBuffer 的实现类内部，使用了 Cleaner （虚引用）来监测 ByteBuffer 对象，一旦ByteBuffer 对象被垃圾回收，那么就会由 ReferenceHandler 线程通过 Cleaner 的 clean 方法调用 freeMemory 来释放直接内存","tags":[{"name":"JVM","slug":"JVM","permalink":"http://yzy755.github.io/tags/JVM/"}]},{"title":"MQ业务解耦","date":"2018-09-03T09:00:53.000Z","path":"2018/09/03/MQ业务解耦/","text":"天使排班中有工时存欠的概念，意思是记录护士姐姐们相比一周的标准工时多或少工作的时长，作为统计工作情况的一个依据，存欠值守用户手动输入、实际排班时长、请假以及加班时长的影响，涉及到很多个业务模块，若让业务模块每次数据变更都去计算存欠值耦合就太过严重，所以用MQ解耦 业务模块每次数据变更，比如加班申请通过后发布加班时长增加的消息，存欠统计模块订阅需要的消息 12345678910111213141516171819202122private void sendMqMsg(HcContext context, SchedulingOvertimeInfo schedulingOvertimeInfo, String type) &#123; try &#123; SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd\"); GetWeekBeginEndVo weekBeginEnd = DateUtil.getWeekBeginEnd(dateFormat.parse(schedulingOvertimeInfo.getOvertimeDate())); // 消息内容 ChangedMqMsg changedMqMsg = new ChangedMqMsg(); changedMqMsg.setBeginDate(weekBeginEnd.getBeginDate()); changedMqMsg.setEndDate(weekBeginEnd.getEndDate()); changedMqMsg.setDepartmentId(schedulingOvertimeInfo.getDepartmentId()); changedMqMsg.setuId(schedulingOvertimeInfo.getuId()); changedMqMsg.setOvertimeDuration(\"minus\".equals(type) ? 0f : schedulingOvertimeInfo.getOvertimeDuration()); // 入队 ComponentCommonMsg cmsg = new ComponentCommonMsg(); cmsg.setNotifyType(MqEnum.OVERTIME_DURATION_CHANGED.getId()); cmsg.setNotifyMsg(JSON.toJSONString(changedMqMsg)); commonTopicMsgProducer.sendMessage(cmsg); &#125; catch (ParseException e) &#123; logger.error(\"s:&#123;&#125; 日期转换失败:&#123;&#125;\", context, CommonUtils.getStackTrace(e)); &#125; &#125;","tags":[{"name":"activityMQ","slug":"activityMQ","permalink":"http://yzy755.github.io/tags/activityMQ/"},{"name":"海鹚","slug":"海鹚","permalink":"http://yzy755.github.io/tags/海鹚/"}]},{"title":"shiro全面的权限方案","date":"2018-05-12T09:17:53.000Z","path":"2018/05/12/shiro全面的权限方案/","text":"天使排班基于微信的用户体系，在系统中用户的角色和权限全靠数据库查询和代码控制，没有一个强大简洁的权限控制框架实在不方便，于是引入了以前使用过的shiro，并在使用上进行了加强，集成了redis权限缓存以及基于redis的sessionDAO，全面支持分布式。 1.认证认证通过微信或钉钉的认证，认证后在天使排版中只需在shiro中默认标记为认证通过即可 2.授权2.1权限控制2.1.1基于角色的访问控制RBAC基于角色的访问控制（Role-Based Access Control）是以角色为中心进行访问控制，比如：主体的角色为管理员可以排班，查询成员信息等，访问控制流程如下： 上图中的判断逻辑代码可以理解为：123if(主体.hasRole(\"管理员角色id\"))&#123; 排班&#125; 缺点：以角色进行访问控制粒度较粗，如果上图中排班所需要的角色变化为创建者和管理员，此时就需要修改判断逻辑为“判断主体的角色是否是创建者或管理员”，系统可扩展性差。修改代码如下：if(主体.hasRole(“管理员角色id”) || 主体.hasRole(“创建者角色id”)){ 排班} 2.1.2基于资源的访问控制RBAC基于资源的访问控制（Resource-Based Access Control）是以资源为中心进行访问控制，比如：主体必须具有排班权限才可以排班等，访问控制流程如下： 上图中的判断逻辑代码可以理解为：if(主体.hasPermission(“排班权限标识”)){ 排班} 优点：系统设计时定义好排班的权限标识，即使排班所需要的角色变化为创建者和管理员也只需要将“排班权限”添加到“管理角色”的权限列表中，判断逻辑不用修改，系统可扩展性强。 2.1.3基于url拦截基于url拦截是企业中常用的权限管理方法，实现思路是：将系统操作的每个url配置在权限表中，将权限对应到角色，将角色分配给用户，用户访问系统功能通过Filter进行过虑，过虑器获取到用户访问的url，只要访问的url是用户分配角色中的url则放行继续访问。 如下图： 2.2权限模型对主体、资源、权限通过数据模型表示。 主体（账号、密码）资源（资源名称、访问地址）权限（权限名称、资源id）角色（角色名称）角色和权限关系（角色id、权限id）主体和角色关系（主体id、角色id） 通常企业开发中将资源和权限表合并为一张权限表，如下：资源（资源名称、访问地址）权限（权限名称、资源id）合并为：权限（权限名称、资源名称、资源访问地址）如下图： 上图常被称为权限管理的通用模型，在开发中根据系统自身的特点还会对上图进行修改，字段可以个性化。 3. Shiro3.1 Shiro架构 3.1.1 SubjectSubject即主体，外部应用与subject进行交互，subject记录了当前操作用户，将用户的概念理解为当前操作的主体，可能是一个通过浏览器请求的用户，也可能是一个运行的程序。 Subject在shiro中是一个接口，接口中定义了很多认证授相关的方法，外部程序通过subject进行认证授，而subject是通过SecurityManager安全管理器进行认证授权 3.1.2 SecurityManagerSecurityManager即安全管理器，对全部的subject进行安全管理，它是shiro的核心，负责对所有的subject进行安全管理。通过SecurityManager可以完成subject的认证、授权等，实质上SecurityManager是通过Authenticator进行认证，通过Authorizer进行授权，通过SessionManager进行会话管理等。SecurityManager是一个接口，继承了Authenticator, Authorizer, SessionManager这三个接口。 3.1.3 AuthenticatorAuthenticator即认证器，对用户身份进行认证，Authenticator是一个接口，shiro提供ModularRealmAuthenticator实现类，通过ModularRealmAuthenticator基本上可以满足大多数需求，也可以自定义认证器。 3.1.4 AuthorizerAuthorizer即授权器，用户通过认证器认证通过，在访问功能时需要通过授权器判断用户是否有此功能的操作权限。 3.1.5 realmRealm即领域，相当于datasource数据源，securityManager进行安全认证需要通过Realm获取用户权限数据，比如：如果用户身份数据在数据库那么realm就需要从数据库获取用户身份信息。注意：不要把realm理解成只是从数据源取数据，在realm中还有认证授权校验的相关的代码。其中，最基础的是 Realm 接口，AuthenticationRealm 负责认证，AuthorizingRealm负责授权，通常自定义的 realm 继承AuthorizingRealm 。 3.1.6 sessionManagersessionManager即会话管理，shiro框架定义了一套会话管理，它不依赖web容器的session，所以shiro可以使用在非web应用上，也可以将分布式应用的会话集中在一点管理，此特性可使它实现单点登录。 3.1.7 SessionDAOSessionDAO即会话dao，是对session会话操作的一套接口，比如要将session存储到数据库，可以通过jdbc将会话存储到数据库。通过SessionDao管理session数据，针对个性化的session数据存储需要使用sessionDao 3.1.8 CacheManagerCacheManager即缓存管理，将用户权限数据存储在缓存，这样可以提高性能。Shiro有默认的cache实现，是通过自定义map实现的，可整合ehcache或者redis实现cache 3.1.9 CryptographyCryptography即密码管理，shiro提供了一套加密/解密的组件，方便开发。比如提供常用的散列、加/解密等功能。 3.2 shiro的jar包与其它java开源框架类似，将shiro的jar包加入项目就可以使用shiro提供的功能了。shiro-core是核心包必须选用，还提供了与web整合的shiro-web、与spring整合的shiro-spring、与任务调度quartz整合的shiro-quartz等，下边是shiro各jar包的maven坐标。123456789101112131415161718192021222324252627 &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-web&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-quartz&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt;也可以通过引入shiro-all包括shiro所有的包： &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-all&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; 3.3 shiro入口Web.xml:Stringmvc: 3.4 shiro认证认证流程 1、web初始化securityManager。2、调用subject.login方法主体提交认证，提交的token3、securityManager进行认证，securityManager最终由ModularRealmAuthenticator进行认证。4、ModularRealmAuthenticator给Realm传入token5、Realm根据输入的token（UsernamePasswordToken）调用doGetAuthenticationInfo从数据库查询用户信息，根据账号查询用户信息（账号和密码）如果查询到用户信息，就给ModularRealmAuthenticator返回用户信息（账号和密码） 如果查询不到，就给ModularRealmAuthenticator返回null 6、ModularRealmAuthenticator接收Realm返回Authentication认证信息如果返回的认证信息是null，ModularRealmAuthenticator抛出异常（org.apache.shiro.authc.UnknownAccountException） 如果返回的认证信息不是null（说明数据库找到了用户），对Realm返回用户密码 和 token中的密码 进行对比，如果不一致抛出异常（org.apache.shiro.authc.IncorrectCredentialsException） 3.5 shiro授权授权流程 1、对subject进行授权，调用方法isPermitted（”permission串”）2、SecurityManager执行授权，通过ModularRealmAuthorizer执行授权3、ModularRealmAuthorizer执行realm（从数据库查询权限数据调用realm的授权方法：doGetAuthorizationInfo 4、realm从数据库查询权限数据，返回ModularRealmAuthorizer5、ModularRealmAuthorizer调用PermissionResolver进行权限串比对6、如果比对后，isPermitted中”permission串”在realm查询到权限数据中，说明用户访问permission串有权限，否则 没有权限，抛出异常。3.6自定义realm自定义realm继承AuthorizingRealm，其中两个最重要的方法doGetAuthenticationInfo认证方法、doGetAuthorizationInfo授权方法，重载两个方法，在自定义realm中注入角色和权限的service进行查询。 3.6.1认证方法根据shiro认证流程，在调用subject.login()方法后会进入认证方法，在该方法中将用户名和用户密码写入shiro认证信息中。由于天使排班没有自己的账号密码模块，可以将用户id作为用户名，密码设置为空进行记录： 登陆：认证： 3.6.2授权方法授权方法触发的方式有很多，简单的方式可以在认证方法中显式调用，正常的方式是在用户访问受保护的资源时进行授权，这个前提是在shiro的配置中配置哪些资源是需要权限访问的，配置有两种方式，第一种方式：在shiroFilter总过滤器中，配置url对应需要的角色或权限比如：第二种方式：在方法上添加注解，方法可以使service方法，也可以是controller，建议在controller方法上加，service方法由于复用的关系，加权限控制不适合，比如：授权方法实现： 4.扩展shiro4.1需求在线修改用户角色或权限实时生效 4.2为什么要扩展在用户认证和授权完成后，为了提高性能，使用了cacheManage组件缓存了用户的角色权限信息，在用户退出登录之前不会再次请求授权方法，需要在适当的时机清除指定用户的权限缓存，指定用户在缓存清空后访问受保护的资源之前重新进行授权。 4.3怎么做在shiroFilter核心过滤器中，提供了filters参数，这个参数记录了能够控制资源访问的权限过滤器链，初始化过程中shiro会注册默认的filter，shiro默认提供如下过滤器： 在这基础上自定义自己的过滤器，这里选择继承AccessControlFilter，重载两个方法：isAccessAllowed：即是否允许访问，返回 true 表示允许； onAccessDenied：表示访问拒绝时是否自己处理，如果返回 true 表示自己不处理且继续拦截器链执行，返回 false 表示自己已经处理了（比如重定向到另一个页面）。 isAccessAllowed方法默认返回false不允许访问，随后就进入onAccessDenied方法，然后就可以自己处理当前用户了，判断当前用户session中是否被标记为修改了权限，如果被标记了的话，就清除当前用户的缓存，最后返回true，如下：配置如下： 如何标记用户，在管理员修改用户的角色权限逻辑中，根据被修改的用户id，找到其对应的session并标记，这里需要在修改的service中注入sessionDao对象，从而获取想要的session。 5.数据库设计权限表 角色权限关联表 角色表、用户表、用户角色关联表沿用以前的设计 海鹚的session是重写的，sessionId和cookiename都是自定义的，与shiro的session不能通用，重写sessionDAO实现session同步，屏蔽公司的filter，自定义sessionId和cookiename","tags":[{"name":"海鹚","slug":"海鹚","permalink":"http://yzy755.github.io/tags/海鹚/"},{"name":"shiro","slug":"shiro","permalink":"http://yzy755.github.io/tags/shiro/"}]},{"title":"TensorFlow的Python API","date":"2017-05-25T02:17:53.000Z","path":"2017/05/25/TensorFlow的Python API/","text":"tensorflow的java api极限性还是很大，至今也是能找到linux和mac的库文件，再加上决定使用superset作为olap系统，正好可以在superset上集成Python版本的TensorFlow继续想使用现成的图像识别模型做一个简单的demo，网上有现成的训练完的模型源码： # Copyright 2015 Google Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an &quot;AS IS&quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # ============================================================================== &quot;&quot;&quot;Simple image classification with Inception. Run image classification with Inception trained on ImageNet 2012 Challenge data set. This program creates a graph from a saved GraphDef protocol buffer, and runs inference on an input JPEG image. It outputs human readable strings of the top 5 predictions along with their probabilities. Change the --image_file argument to any jpg image to compute a classification of that image. Please see the tutorial and website for a detailed description of how to use this script to perform image recognition. https://tensorflow.org/tutorials/image_recognition/ &quot;&quot;&quot; from __future__ import absolute_import from __future__ import division from __future__ import print_function import os.path import re import sys import tarfile import numpy as np from six.moves import urllib import tensorflow as tf FLAGS = tf.app.flags.FLAGS # classify_image_graph_def.pb: # Binary representation of the GraphDef protocol buffer. # imagenet_synset_to_human_label_map.txt: # Map from synset ID to a human readable string. # imagenet_2012_challenge_label_map_proto.pbtxt: # Text representation of a protocol buffer mapping a label to synset ID. tf.app.flags.DEFINE_string( &apos;model_dir&apos;, &apos;/tmp/imagenet&apos;, &quot;&quot;&quot;Path to classify_image_graph_def.pb, &quot;&quot;&quot; &quot;&quot;&quot;imagenet_synset_to_human_label_map.txt, and &quot;&quot;&quot; &quot;&quot;&quot;imagenet_2012_challenge_label_map_proto.pbtxt.&quot;&quot;&quot;) tf.app.flags.DEFINE_string(&apos;image_file&apos;, &apos;&apos;, &quot;&quot;&quot;Absolute path to image file.&quot;&quot;&quot;) tf.app.flags.DEFINE_integer(&apos;num_top_predictions&apos;, 5, &quot;&quot;&quot;Display this many predictions.&quot;&quot;&quot;) # pylint: disable=line-too-long DATA_URL = &apos;http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz&apos; # pylint: enable=line-too-long class NodeLookup(object): &quot;&quot;&quot;Converts integer node ID&apos;s to human readable labels.&quot;&quot;&quot; def __init__(self, label_lookup_path=None, uid_lookup_path=None): if not label_lookup_path: label_lookup_path = os.path.join( FLAGS.model_dir, &apos;imagenet_2012_challenge_label_map_proto.pbtxt&apos;) if not uid_lookup_path: uid_lookup_path = os.path.join( FLAGS.model_dir, &apos;imagenet_synset_to_human_label_map.txt&apos;) self.node_lookup = self.load(label_lookup_path, uid_lookup_path) def load(self, label_lookup_path, uid_lookup_path): &quot;&quot;&quot;Loads a human readable English name for each softmax node. Args: label_lookup_path: string UID to integer node ID. uid_lookup_path: string UID to human-readable string. Returns: dict from integer node ID to human-readable string. &quot;&quot;&quot; if not tf.gfile.Exists(uid_lookup_path): tf.logging.fatal(&apos;File does not exist %s&apos;, uid_lookup_path) if not tf.gfile.Exists(label_lookup_path): tf.logging.fatal(&apos;File does not exist %s&apos;, label_lookup_path) # Loads mapping from string UID to human-readable string proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines() uid_to_human = {} p = re.compile(r&apos;[n\\d]*[ \\S,]*&apos;) for line in proto_as_ascii_lines: parsed_items = p.findall(line) uid = parsed_items[0] human_string = parsed_items[2] uid_to_human[uid] = human_string # Loads mapping from string UID to integer node ID. node_id_to_uid = {} proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines() for line in proto_as_ascii: if line.startswith(&apos; target_class:&apos;): target_class = int(line.split(&apos;: &apos;)[1]) if line.startswith(&apos; target_class_string:&apos;): target_class_string = line.split(&apos;: &apos;)[1] node_id_to_uid[target_class] = target_class_string[1:-2] # Loads the final mapping of integer node ID to human-readable string node_id_to_name = {} for key, val in node_id_to_uid.items(): if val not in uid_to_human: tf.logging.fatal(&apos;Failed to locate: %s&apos;, val) name = uid_to_human[val] node_id_to_name[key] = name return node_id_to_name def id_to_string(self, node_id): if node_id not in self.node_lookup: return &apos;&apos; return self.node_lookup[node_id] def create_graph(): &quot;&quot;&quot;Creates a graph from saved GraphDef file and returns a saver.&quot;&quot;&quot; # Creates graph from saved graph_def.pb. with tf.gfile.FastGFile(os.path.join( FLAGS.model_dir, &apos;classify_image_graph_def.pb&apos;), &apos;rb&apos;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) _ = tf.import_graph_def(graph_def, name=&apos;&apos;) def run_inference_on_image(image): &quot;&quot;&quot;Runs inference on an image. Args: image: Image file name. Returns: Nothing &quot;&quot;&quot; if not tf.gfile.Exists(image): tf.logging.fatal(&apos;File does not exist %s&apos;, image) image_data = tf.gfile.FastGFile(image, &apos;rb&apos;).read() # Creates graph from saved GraphDef. create_graph() with tf.Session() as sess: # Some useful tensors: # &apos;softmax:0&apos;: A tensor containing the normalized prediction across # 1000 labels. # &apos;pool_3:0&apos;: A tensor containing the next-to-last layer containing 2048 # float description of the image. # &apos;DecodeJpeg/contents:0&apos;: A tensor containing a string providing JPEG # encoding of the image. # Runs the softmax tensor by feeding the image_data as input to the graph. softmax_tensor = sess.graph.get_tensor_by_name(&apos;softmax:0&apos;) predictions = sess.run(softmax_tensor, {&apos;DecodeJpeg/contents:0&apos;: image_data}) predictions = np.squeeze(predictions) # Creates node ID --&gt; English string lookup. node_lookup = NodeLookup() top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1] for node_id in top_k: human_string = node_lookup.id_to_string(node_id) score = predictions[node_id] print(&apos;%s (score = %.5f)&apos; % (human_string, score)) def maybe_download_and_extract(): &quot;&quot;&quot;Download and extract model tar file.&quot;&quot;&quot; dest_directory = FLAGS.model_dir if not os.path.exists(dest_directory): os.makedirs(dest_directory) filename = DATA_URL.split(&apos;/&apos;)[-1] filepath = os.path.join(dest_directory, filename) if not os.path.exists(filepath): def _progress(count, block_size, total_size): sys.stdout.write(&apos;\\r&gt;&gt; Downloading %s %.1f%%&apos; % ( filename, float(count * block_size) / float(total_size) * 100.0)) sys.stdout.flush() filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress) print() statinfo = os.stat(filepath) print(&apos;Succesfully downloaded&apos;, filename, statinfo.st_size, &apos;bytes.&apos;) tarfile.open(filepath, &apos;r:gz&apos;).extractall(dest_directory) def main(_): maybe_download_and_extract() image = (FLAGS.image_file if FLAGS.image_file else os.path.join(FLAGS.model_dir, &apos;cropped_panda.jpg&apos;)) run_inference_on_image(image) if __name__ == &apos;__main__&apos;: tf.app.run() 这是个可以直接运行py文件：python classify_image.py 就可以识别cropped_panda.jpg为大熊猫，程序会下载训练好的pb模型文件和物品分类大全txt文件，然后在 https://github.com/airbnb/superset 下载superset源码，在view包的core.py中拓展一个文件上传功能，将上传的文件条用上面的识别方法，就可以做到简单的图形识别，整个流程下来问题主要还是算法模型的生成。。。在部署superset过程中也遇到很多坑，官方文档上是说修改完源码后要重新对前端打包，基本可以参照 https://fangyeqing.github.io/2017/03/04/superset%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/ 这上面的教程，后台编译就比较简单了，在superset根目录下执行 python setup.py install 就行，然后参照前面写的superset搭建启动的方式即可","tags":[{"name":"python","slug":"python","permalink":"http://yzy755.github.io/tags/python/"},{"name":"AI","slug":"AI","permalink":"http://yzy755.github.io/tags/AI/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yzy755.github.io/tags/TensorFlow/"}]},{"title":"TensorFlow的java API","date":"2017-05-17T10:17:53.000Z","path":"2017/05/17/TensorFlow的java API/","text":"对数学不好的人来讲，阅读TensorFlow实在是一件让人头皮发麻的事情，现在接触的这个大数据分析项目是想将使用TensorFlow写的算法打包供外部使用以及外部系统以rest接口方式来调用算法得到结果，写算法和调用这两个工作肯定是要分离的，暂且不管TensorFlow本身如何使用，研究了下用java调用TensorFlow的方式。从 https://codeload.github.com/tensorflow/tensorflow/zip/v1.1.0 下载源码电脑上用不超过3.5版本（anaconda3 4.2版本）的Python： pip install tensorflow 直接安装然后就发现了很奇怪的地方，https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md 上对TensorFlow for java的描述是说有linux、Mac、windows的库，但是在源码tensorflow-1.1.0\\tensorflow\\java目录下的readme文件中只给出了linux和mac的下载地址，无奈只能在先在linux虚拟机中尝试了，根据那个readme文件可以下载到.jar用于java调用TensorFlow api，还有一个.so文件用于底层调用native方法库，这样也不难理解，但是这样其实失去了java最强的跨平台特性。。。建一个简单的java project，将下载的jar包加入classpath，写个main方法，一句话试下能不能用：System.out.println(TensorFlow.version());报错：TensorFlow Java API methods will throw an UnsatisfiedLinkError unless native code shared libraries are loaded，意思是java的library中没有相应的库文件，执行System.out.println(System.getProperty(“java.library.path”));看下这台电脑的库路径是什么，将so文件放进去即可，或者是在该工程的jdk中加入自定义的库路径，然后就可以执行查看版本的方法了， 将源码中的tensorflow\\java\\src代码拷贝到工程中，其中test包中都可以执行尝试下，最符合我研究目标的一个类躲在tensorflow\\java\\src\\main\\java\\org\\tensorflow\\examples包中，里边是一个调用模型去识别图片中的物体的类：LabelImage.java https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip 下载算法模型和物品种类列表解压到目录下，这里是：/tmp/graph/ 创建一个调用类，main方法就一句话：LabelImage.main(new String[] { “/tmp/graph/“, “/tmp/graph/plane.jpg” });当然要准备一张合适的图片，然后他就给你识别，这是一张战斗飞机的图片，而识别的结果为：BEST MATCH: airliner (45.18% likely) ，意思是班机，都是飞机，八九不十 源码中调用的是一个.pb文件，我的理解是该文件是用TensorFlow写好算法并训练完毕生成的模型，就以类似这种文件为界限，生成该文件的工作交给算法设计人员，调用该文件的工作交给技术人员，以后的算法打包也好，webservice调用也好都好理解。 其实使用java这种方法去调用TensorFlow，在不了解TensorFlow使用的情况下还是写不出来什么代码，只是可以规避现有的java技术人员重新学习Python和搭建python web服务的时间成本和风险罢了，有时间的话最好还是用Python接，没有异构的问题。 思考1：pb模型文件一旦产生如何提高学习的准确率，就像上面识别飞机也只有45.18%的概率，今日头条的推荐应该也是用这种训练学习的方式，你用得越多越久，它就越知道你想看什么，然后达到推荐的目的，如何保证持续学习训练。。。 猜想：设置一个节点，无论是从时间维度还是数据量大小维度考虑，这个节点将获取的数据添加到训练集，重新训练得出模型","tags":[{"name":"AI","slug":"AI","permalink":"http://yzy755.github.io/tags/AI/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yzy755.github.io/tags/TensorFlow/"},{"name":"java","slug":"java","permalink":"http://yzy755.github.io/tags/java/"}]},{"title":"基于python+flask+mysql的web开发初探","date":"2017-05-12T07:40:53.000Z","path":"2017/05/12/基于python+flask+mysql的web开发初探/","text":"由于用Python开发一个Web框架十分容易，所以Python有上百个开源的Web框架，当下流行的是Flask,Django等Flask是一个使用 Python 编写的轻量级 Web 应用框架。其 WSGI 工具箱采用 Werkzeug ，模板引擎则使用 Jinja2 。搭建的大致步骤和常见的问题： 1.安装anaconda，anaconda里面集成了很多关于python科学计算的第三方库，主要是安装方便，而python是一个编译器，如果不使用anaconda，那么安装起来会比较痛苦，各个库之间的依赖性就很难连接的很好 2.安装mysql 3.安装mysql-python，命令:pip install MySql-python 错误1：Microsoft Visual C++ 14.0 is required. 升级.NET Framework 版本到4.5.1 从错误提示的url下载，下载后安装visualcppbuildtools_full 3.安装mysql connector, 下载地址：https://dev.mysql.com/downloads/connector/python/我的系统为64， 下载的是mysql-connector-python-2.1.5-py3.4-winx64，还是报错，后来注意到寻找的目录是Program Files (x86)，又下了个32位的安装。错误过去了。但是又来新的错误： LINK : error LNK2001: unresolved external symbol _DllMainCRTStartup build\\lib.win-amd64-3.5\\_mysql.cp35-win_amd64.pyd : fatal error LNK1120: 56 unresolved externalserror: command &apos;C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 14.0\\\\VC\\\\BIN\\\\x86_amd64\\\\link.exe&apos; failed with exit status 1120 5.安装第三方包pymysql。下载地址：https://pypi.python.org/pypi/PyMySQL#downloads下载PyMySQL-0.7.11-py2.py3-none-any.whl，使用pip install PyMySQL-0.7.11-py2.py3-none-any.whl 即可，再执行pip install MySql-python就成功了 python引入mysql方法：import pymysql as MySQLdb 首次尝试python的web开发：源码: db.py: host=&quot;127.0.0.1&quot; user=&quot;root&quot; password=&quot;123456&quot; charset=&quot;utf8&quot; database=&quot;test&quot; port=3306 service.py: import pymysql as MySQLdb import sys import db class AService(object): def getA(self,id): conn = MySQLdb.connect(host=db.host,user=db.user,passwd=db.password,port=db.port,db=db.database,charset=db.charset) result=[] try: cursor = conn.cursor() cursor.execute(&quot;select id,sname from student where id=&apos;%d&apos;&quot;%(id)) result = cursor.fetchone() finally: cursor.close() conn.close() return result hello.py: from flask import Flask, jsonify import service import sys app = Flask(__name__) @app.route(&apos;/service&apos;, methods=[&apos;GET&apos;]) def getSerivice(): mservice=service.AService() result = mservice.getA(1) json = &quot;&quot; json +=&quot;{&quot; json +=&quot;&apos;id&apos;:&quot;+str(result[0])+&quot;,&quot; json +=&quot;&apos;sname&apos;:&apos;&quot;+result[1]+&quot;&apos;&quot; json +=&quot;}&quot; return json; if __name__==&quot;__main__&quot;: app.run() 在cmd中执行 python hello.py打开浏览器 http://localhost:5000出现 {‘id’:1,’sname’:’yizeyuan’}成功！ 这个例子太简单，实际上可以像平时javaweb开发一样使用MVC模式，上面的hello.py是控制器，service.py是model,而view我们同样可以使用html，Flask使用jinja2渲染使用方式： from flask import Flask, request, render_template #加上render_template当请求处理完成返回一个模板以及变量 return render_template(‘index.html’, message=’欢迎使用flask’, username=’yizeyuan’)首页的html代码为： &lt;html&gt; &lt;head&gt; &lt;title&gt;index&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 style=&quot;font-style:italic&quot;&gt;Home&lt;/h1&gt; {{message}} 欢迎你，{{username}} &lt;/body&gt; &lt;/html&gt; 很像angularjs有木有！","tags":[{"name":"python","slug":"python","permalink":"http://yzy755.github.io/tags/python/"},{"name":"web开发","slug":"web开发","permalink":"http://yzy755.github.io/tags/web开发/"}]},{"title":"TensorFlow搭建和TensorBoard可视化的使用","date":"2017-05-09T10:17:53.000Z","path":"2017/05/09/TensorFlow搭建和TensorBoard可视化的使用/","text":"TensorFlow™ 是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。TensorFlow 最初由Google大脑小组（隶属于Google机器智能研究机构）的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域。1.Centos6.x默认使用的Python版本为2.6.6，而TensorFlow需要的Python版本起步为2.7以上，首先升级Python版本，已2.7.3为例： # wget https://www.python.org/ftp/python/2.7.3/Python-2.7.3.tgz # tar -xvjf Python-2.7.3.tar.bz2 # mkdir /usr/local/python27 # ./configure --prefix=/usr/local/python27 # Make # make install 以上安装好了2.7.3，但此时没有覆盖老版本，再将原来/usr/bin/python链接改为别的名字： # mv /usr/bin/python /usr/bin/python_old 再建立新版本python的软链接： # ln -s /usr/local/python27/bin/python2.7 /usr/bin/python 再输入 # python --version 会出现2.7.3则说明成功 但是，基于Python编写的yum不兼容2.7以上版本，所以修改yum命令指定的Python版本: # vi /usr/bin/yum 将第一句 # !/usr/bin/python 改为 # !/usr/bin/python2.6 即可 安装setuptool,后续操作要运行很多py文件，没他不行 # wget --no-check-certificate https://pypi.python.org/packages/source/s/setuptools/setuptools-1.4.2.tar.gz # tar -xvf setuptools-1.4.2.tar.gz # cd setuptools-1.4.2 # python setup.py install 2.升级pip，Python Index Package。类似linux下的yum，安装并管理python软件包，Python升级了版本pip也要升级相应版本，下载pip9.0.1 # wget https://pypi.python.org/packages/11/b6/abcb525026a4be042b486df43905d6893fb04f05aac21c32c638e939e447/pip-9.0.1.tar.gz# md5=35f01da33009719497f01a4ba69d63c9 # tar zxvf pip-9.0.1.tar.gz # cd pip-9.0.1 # python setup.py install 3.执行： # pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl 正常情况下pip会自动下载依赖包并安装，但是也有可能会报依赖没有找到的情况，如果出现此情况见附录，在最后可能会报错，在执行一次就好了 4.然后输入命令： # python 出现 &gt;&gt;&gt; 再输入：improt ssl再输入import tensorflow as tf 会出现/lib64/libc.so.6: version `GLIBC_2.15’ not found 的错误，这是由于tensorflow0.80版本编译的时候使用GLIBC_2.15，系统自带的是GLIBC_2.12，所以报错了。安装gcc # yum install gcc 下载c++库glibc # wget http://ftp.gnu.org/pub/gnu/glibc/glibc-2.17.tar.xz # xz -d glibc-2.17.tar.xz # tar -xvf glibc-2.17.tar # cd glibc-2.17 # mkdir build # cd build # ../configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin # make &amp;&amp; make install 输入strings /lib64/libc.so.6|grep GLIBC发现有我们的2.15版本 5.再执行第5步，发现报/usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.14’ not found的错误，输入命令strings /usr/lib64/libstdc++.so.6 | grep GLIBCXX 发现没有支持3.4.14版本，去csdn下载一个高版本的libstdc++.so.6，比如说libstdc++.so.6.0.20，网址：http://download.csdn.net/download/arackethis/8395651，将文件放到/usr/lib64/下，在该目录下执行命令： # chmod +x libstdc++.so.6.0.20 # rm libstdc++.so.6 # ln -s libstdc++.so.6.0.20 libstdc++.so.6 # strings /usr/lib64/libstdc++.so.6 | grep GLIBCXX 发现支持了3.4.14版本 再执行第五步发现没有报错了，就此TensorFlow搭建成功 Ps:第三步中依赖报错的解决方式1.安装six # wget https://pypi.python.org/packages/c8/0a/b6723e1bc4c516cb687841499455a8505b446 07ab535 be01091c0f24f079/six-1.10.0-py2.py3-none-any.whl#md5=3ab558cf5d4f7a72611d5 9a81a31 5dc8 #下载指令 # pip install six-1.10.0-py2.py3-none-any.whl #安装指令 2.安装numpy，下载地址：http://jaist.dl.sourceforge.net/project/numpy/NumPy/1.11.2rc1/，解压使用python安装3.安装protobuf #wget https://pypi.python.org/packages/0f/53/e43b226f83a5a542c16695e9624b7bd2bde4ad016776c 7c3233901bcf5b4/protobuf-3.2.0-cp27-cp27mu-manylinux1_x86_64.whl#md5=a1a807fee3a 7df784e171837853cc29d #下载指令 # pip install protobuf-3.2.0-cp27-cp27mu-manylinux1_x86_64.whl 这一步可能会用pip安装 提示找不到ssl模块，参考http://blog.csdn.net/qq_25560423/article/details/62055497 Ps:正文中第二步pip另外的安装方式：pip安装命令：yum install python-pip python-devel 补充TensorFlow中TensorBorad可视化组件的使用：如何更直观的观察数据在神经网络中的变化，或是已经构建的神经网络的结构，Tensorflow自带了可视化模块Tensorboard，并且能更直观的看见整个神经网络的结构。 TensorBoard的输入是tensorflow保存summary data的日志文件。日志文件名的形式如：events.out.tfevents.1467809796.lei-All-Series 或 events.out.tfevents.1467809800.lei-All-Series。TensorBoard可读的summary data有scalar，images，audio，histogram和graph。那么怎么把这些summary data保存在日志文件中呢？数值如学习率，损失函数用scalar_summary函数。tf.scalar_summary(节点名称，获取的数据) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) tf.scalar_summary(‘accuracy’, accuracy) 各层网络权重，偏置的分布，用histogram_summary函数 preactivate = tf.matmul(input_tensor, weights) + biases tf.histogram_summary(layer_name + ‘/pre_activations’, preactivate) 其他几种summary data也是同样的方式获取，只是对应的获取函数名称换一下。这些获取summary data函数节点和graph是独立的，调用的时候也需要运行session。当需要获取的数据较多的时候，我们一个一个去保存获取到的数据，以及一个一个去运行会显得比较麻烦。tensorflow提供了一个简单的方法，就是合并所有的summary data的获取函数，保存和运行只对一个对象进行操作。比如，写入默认路径中，比如/tmp/mnist_logs (by default) merged = tf.merge_all_summaries() train_writer = tf.train.SummaryWriter(FLAGS.summaries_dir + ‘/train’, sess.graph) test_writer = tf.train.SummaryWriter(FLAGS.summaries_dir + ‘/test’) SummaryWriter从tensorflow获取summary data，然后保存到指定路径的日志文件中。以上是在建立graph的过程中，接下来执行，每隔一定step，写入网络参数到默认路径中，形成最开始的文件：events.out.tfevents.1467809796.lei-All-Series 或 events.out.tfevents.1467809800.lei-All-Series。 for i in range(FLAGS.max_steps): if i % 10 == 0: # Record summaries and test-set accuracy summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False)) test_writer.addsummary(summary, i) print(‘Accuracy at step %s: %s’ % (i, acc)) else: # Record train set summarieis, and train summary, = sess.run([merged, train_step], feed_dict=feed_dict(True)) train_writer.add_summary(summary, i) 源码： ‘’’ Created on May 9, 2017 @author: root &apos;&apos;&apos; # Copyright 2015 The TensorFlow Authors. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the &apos;License&apos;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an &apos;AS IS&apos; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # ============================================================================== &quot;&quot;&quot;A simple MNIST classifier which displays summaries in TensorBoard. This is an unimpressive MNIST model, but it is a good example of using tf.name_scope to make a graph legible in the TensorBoard graph explorer, and of naming summary tags so that they are grouped meaningfully in TensorBoard. It demonstrates the functionality of every TensorBoard dashboard. &quot;&quot;&quot; import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_boolean(&apos;fake_data&apos;, False, &apos;If true, uses fake data &apos; &apos;for unit testing.&apos;) flags.DEFINE_integer(&apos;max_steps&apos;, 1000, &apos;Number of steps to run trainer.&apos;) flags.DEFINE_float(&apos;learning_rate&apos;, 0.001, &apos;Initial learning rate.&apos;) flags.DEFINE_float(&apos;dropout&apos;, 0.9, &apos;Keep probability for training dropout.&apos;) flags.DEFINE_string(&apos;data_dir&apos;, &apos;/tmp/data&apos;, &apos;Directory for storing data&apos;) flags.DEFINE_string(&apos;summaries_dir&apos;, &apos;/tmp/mnist_logs&apos;, &apos;Summaries directory&apos;) def train(): # Import data mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True, fake_data=FLAGS.fake_data) sess = tf.InteractiveSession() # Create a multilayer model. # Input placehoolders with tf.name_scope(&apos;input&apos;): x = tf.placeholder(tf.float32, [None, 784], name=&apos;x-input&apos;) y_ = tf.placeholder(tf.float32, [None, 10], name=&apos;y-input&apos;) with tf.name_scope(&apos;input_reshape&apos;): image_shaped_input = tf.reshape(x, [-1, 28, 28, 1]) tf.image_summary(&apos;input&apos;, image_shaped_input, 10) # We can&apos;t initialize these variables to 0 - the network will get stuck. def weight_variable(shape): &quot;&quot;&quot;Create a weight variable with appropriate initialization.&quot;&quot;&quot; initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial) def bias_variable(shape): &quot;&quot;&quot;Create a bias variable with appropriate initialization.&quot;&quot;&quot; initial = tf.constant(0.1, shape=shape) return tf.Variable(initial) def variable_summaries(var, name): &quot;&quot;&quot;Attach a lot of summaries to a Tensor.&quot;&quot;&quot; with tf.name_scope(&apos;summaries&apos;): mean = tf.reduce_mean(var) tf.scalar_summary(&apos;mean/&apos; + name, mean) with tf.name_scope(&apos;stddev&apos;): stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean))) tf.scalar_summary(&apos;sttdev/&apos; + name, stddev) tf.scalar_summary(&apos;max/&apos; + name, tf.reduce_max(var)) tf.scalar_summary(&apos;min/&apos; + name, tf.reduce_min(var)) tf.histogram_summary(name, var) def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu): &quot;&quot;&quot;Reusable code for making a simple neural net layer. It does a matrix multiply, bias add, and then uses relu to nonlinearize. It also sets up name scoping so that the resultant graph is easy to read, and adds a number of summary ops. &quot;&quot;&quot; # Adding a name scope ensures logical grouping of the layers in the graph. with tf.name_scope(layer_name): # This Variable will hold the state of the weights for the layer with tf.name_scope(&apos;weights&apos;): weights = weight_variable([input_dim, output_dim]) variable_summaries(weights, layer_name + &apos;/weights&apos;) with tf.name_scope(&apos;biases&apos;): biases = bias_variable([output_dim]) variable_summaries(biases, layer_name + &apos;/biases&apos;) with tf.name_scope(&apos;Wx_plus_b&apos;): preactivate = tf.matmul(input_tensor, weights) + biases tf.histogram_summary(layer_name + &apos;/pre_activations&apos;, preactivate) activations = act(preactivate, &apos;activation&apos;) tf.histogram_summary(layer_name + &apos;/activations&apos;, activations) return activations hidden1 = nn_layer(x, 784, 500, &apos;layer1&apos;) with tf.name_scope(&apos;dropout&apos;): keep_prob = tf.placeholder(tf.float32) tf.scalar_summary(&apos;dropout_keep_probability&apos;, keep_prob) dropped = tf.nn.dropout(hidden1, keep_prob) y = nn_layer(dropped, 500, 10, &apos;layer2&apos;, act=tf.nn.softmax) with tf.name_scope(&apos;cross_entropy&apos;): diff = y_ * tf.log(y) with tf.name_scope(&apos;total&apos;): cross_entropy = -tf.reduce_mean(diff) tf.scalar_summary(&apos;cross entropy&apos;, cross_entropy) with tf.name_scope(&apos;train&apos;): train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize( cross_entropy) with tf.name_scope(&apos;accuracy&apos;): with tf.name_scope(&apos;correct_prediction&apos;): correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) with tf.name_scope(&apos;accuracy&apos;): accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) tf.scalar_summary(&apos;accuracy&apos;, accuracy) # Merge all the summaries and write them out to /tmp/mnist_logs (by default) merged = tf.merge_all_summaries() train_writer = tf.train.SummaryWriter(FLAGS.summaries_dir + &apos;/train&apos;, sess.graph) test_writer = tf.train.SummaryWriter(FLAGS.summaries_dir + &apos;/test&apos;) tf.initialize_all_variables().run() # Train the model, and also write summaries. # Every 10th step, measure test-set accuracy, and write test summaries # All other steps, run train_step on training data, &amp; add training summaries def feed_dict(train): &quot;&quot;&quot;Make a TensorFlow feed_dict: maps data onto Tensor placeholders.&quot;&quot;&quot; if train or FLAGS.fake_data: xs, ys = mnist.train.next_batch(100, fake_data=FLAGS.fake_data) k = FLAGS.dropout else: xs, ys = mnist.test.images, mnist.test.labels k = 1.0 return {x: xs, y_: ys, keep_prob: k} for i in range(FLAGS.max_steps): if i % 10 == 0: # Record summaries and test-set accuracy summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False)) test_writer.add_summary(summary, i) print(&apos;Accuracy at step %s: %s&apos; % (i, acc)) else: # Record train set summaries, and train if i % 100 == 99: # Record execution stats run_options = tf.RunOptions(trace_level=1) run_metadata = tf.RunMetadata() summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True), options=run_options, run_metadata=run_metadata) train_writer.add_run_metadata(run_metadata, &apos;step%d&apos; % i) train_writer.add_summary(summary, i) print(&apos;Adding run metadata for&apos;, i) else: # Record a summary summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True)) train_writer.add_summary(summary, i) def main(_): if tf.gfile.Exists(FLAGS.summaries_dir): tf.gfile.DeleteRecursively(FLAGS.summaries_dir) tf.gfile.MakeDirs(FLAGS.summaries_dir) train() if __name__ == &apos;__main__&apos;: tf.app.run() 这段源码执行后会在/tmp目录下生成data目录和mnist_logs目录，data是需要分析的数据，mnist_logs是分析的日志，调用TensorBoard可视化运行结果 tensorboard –logdir=/tmp/mnist_logs/train/ 打开链接 http://127.0.0.0:6006 即可看到效果。参考 http://blog.csdn.net/helei001/article/details/51842531","tags":[{"name":"python","slug":"python","permalink":"http://yzy755.github.io/tags/python/"},{"name":"AI","slug":"AI","permalink":"http://yzy755.github.io/tags/AI/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://yzy755.github.io/tags/TensorFlow/"}]},{"title":"superset搭建和简单使用","date":"2017-05-09T09:25:53.000Z","path":"2017/05/09/superset搭建和简单使用/","text":"Superset 是 Airbnb （知名在线房屋短租公司）开源的数据探查与可视化平台（曾用名 Panoramix、Caravel ），该工具在可视化、易用性和交互性上非常有特色，用户可以轻松对数据进行可视化分析。可先直接执行第二步1./usr/local/python27/bin/pip install –upgrade virtualenvpip install –upgrade distributevirtualenv myenv –distribute 2./usr/local/python27/bin/pip install –upgrade superset提示command ‘gcc’ failed with exit status 1的错误 # yum install gcc-c++ # yum install postgresql-devel # yum -y install gcc gcc-c++ kernel-devel # yum -y install python-devel libxslt-devel libffi-devel openssl-devel # yum install openssl-devel python-devel python-sphinx 3.安装MySQL-python-1.2.3.tar.gz安装过程中会出现mysql config not found # yum install mysql-devel 执行find / -name mysql_config在/usr/bin下就出现了这个配置文件，将这个文件复制到MySQL-python-1.2.3解压目录中，再安装即可,报错就执行 # yum install gcc-c++ python-devel.x86_64 cyrus-sasl-devel.x86_64 # pip install thrift_sasl # pip install sasl 再安装即可 4.成功之后将Python的bin目录下的fabmanager、superset、gunicorn文件放到/usr/bin目录下或者建立软连接 # fabmanager create-admin --app superset 报错No module named _sqlite3或者No module named pysqlite2或者其他，需要安装sqlite-devel之后，执行yum install sqlite-devel，重新编译安装Python即可。 # superset db upgrade # superset load_examples # superset init # superset runserver -p 8088 -a 0.0.0.0 会报bash: gunicorn: command not found，执行find / -name gunicorn 查找一下这个命令放哪儿了，然后将它放到/usr/bin中去","tags":[{"name":"python","slug":"python","permalink":"http://yzy755.github.io/tags/python/"},{"name":"数据库分析","slug":"数据库分析","permalink":"http://yzy755.github.io/tags/数据库分析/"}]},{"title":"使用开源软件快速搭建数据分析平台","date":"2017-05-02T08:38:20.000Z","path":"2017/05/02/使用开源软件快速搭建数据分析平台/","text":"部门成立了大数据项目组，技术选型已经由其项目组长完成，但是后台开发人员不足，请求我帮助搭建一个大数据分析平台 整篇文章都是来源于https://my.oschina.net/taogang/blog/630632 ，感谢伟大的开源精神，也就是按照文章介绍的搭建步骤做一点总结，填了两个小坑 1.安装nodejs2.安装git3.安装bower，命令：npm install -g bower4.安装Python环境，anaconda里面集成了很多关于python科学计算的第三方库，安装方便。下载地址：https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/5.进入源码解压后的目录，进入package\\static文件夹，创建名为bower_components的文件夹6.打开cmd使用babel进行jsf的编译，依次执行命令： a)npm install -g babel-cli b)npm install babel-preset-es2015 –save c)npm install babel-preset-react –save d)babel –presets es2015,react –watch js/ –out-dir lib/7.使用bower安装客户端的所有依赖,命令如下： a)bower install8.回到package文件夹，执行命令：python main.py Ps:拓展时若需要更多的开源js组件，可以打开bower.json，在dependency下增加相应的组件名和版本号，然后执行bower install即可。 为以后的大数据方向积累一丁点- -！","tags":[{"name":"python","slug":"python","permalink":"http://yzy755.github.io/tags/python/"},{"name":"数据分析","slug":"数据分析","permalink":"http://yzy755.github.io/tags/数据分析/"}]},{"title":"抢购秒杀功能的并发设计","date":"2017-04-20T06:54:36.000Z","path":"2017/04/20/抢购秒杀功能的并发设计/","text":"最近云课堂系统出现了购买商品出现并发数据错乱的问题，这是类似电商网站所不能接受的现象，果断重构该模块的业务代码刻不容缓- -！其实说到底就是多线程并发请求的数据一致性的问题，当然也有很多处理方法，最先想到的肯定是锁（synchronized），可以明确的是加锁是肯定可以解决该问题的，但是所谓互联网项目，若有朝一日并发请求量有的突破，这种线程阻塞的访问方式肯定是体验糟糕的，所以我想试试其他方式。 首先想到的就是基于单线程，多路复用io（mutiplexing）模式的redis，结合我们的业务是关于众筹抢购的，用户占用众筹名额的记录用redis记录非常适用：redis提供了 INCR key 方法，下面是该方法官方的解释： 对存储在指定key的数值执行原子的加1操作。 如果指定的key不存在，那么在执行incr操作之前，会先将它的值设定为0。 如果指定的key中存储的值不是字符串类型（fix：）或者存储的字符串类型不能表示为一个整数， 那么执行这个命令时服务器会返回一个错误(eq:(error) ERR value is not an integer or out of range)。 这个操作仅限于64位的有符号整型数据。注意看，是原子的加1操作，所以记录众筹的数量后，不管并发多少用户抢购众筹，众筹数都是原子加1，不会出现少加从而出现超卖的情况，加上我们业务控制到达限额数量后停止购买功能。有个问题是用户抢占了名额后迟迟不付款，所以我利用了原先就有的检查未付款订单过期的任务，在检查到未支付的众筹订单过期后使用 DECRBY key decrement 做减操作，该方法官方的解释： 将key对应的数字减decrement。如果key不存在，操作之前，key就会被置为0。如果key的value类型错误或者是个不能表示成数字的字符串，就返回错误。这个操作最多支持64位有符号的正型数字。当热，值的添加和删除肯定也是要用到的，参考官方文档 http://www.redis.cn/这样就释放的未支付抢占的名额，同样这是原子操作。这样整体就保持了高效和线程安全。 一些想法（一些摘抄- -）： 1.Redis为什么使用单进程单线程方式也这么快？ Redis采用的是基于内存的采用的是单进程单线程模型的KV数据库，由C语言编写。官方提供的数据是可以达到100000+的qps。这个数据不比采用单进程多线程的同样基于内存的KV数据库Memcached差。 Redis快的主要原因是： 完全基于内存 数据结构简单，对数据操作也简单 使用多路 I/O 复用模型 多路 I/O 复用模型是利用select、poll、epoll可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。 2.volatile 容易掉的坑 在众筹功能上，占用的众筹数是一个实体变量，我就想volatile关键字不是说是轻量级的synchronized吗，想直接用volatile修饰，其实不然，与 synchronized 块相比，volatile 变量所需的编码较少，并且运行时开销也较少，但是它所能实现的功能也仅是 synchronized的一部分 锁提供了两种主要特性：互斥（mutual exclusion） 和可见性（visibility）。互斥即一次只允许一个线程持有某个特定的锁，因此可使用该特性实现对共享数据的协调访问协议，这样，一次就只有一个线程能够使用该共享数据。可见性要更加复杂一些，它必须确保释放锁之前对共享数据做出的更改对于随后获得该锁的另一个线程是可见的 —— 如果没有同步机制提供的这种可见性保证，线程看到的共享变量可能是修改前的值或不一致的值，这将引发许多严重问题 Volatile 变量具有 synchronized 的可见性特性，但是不具备原子特性。这就是说线程能够自动发现 volatile 变量的最新值。Volatile 变量可用于提供线程安全，但是只能应用于非常有限的一组用例：多个变量之间或者某个变量的当前值与修改后值之间没有约束。因此，单独使用 volatile 还不足以实现计数器、互斥锁或任何具有与多个变量相关的不变式（Invariants）的类（例如 “start &lt;=end”）。 出于简易性或可伸缩性的考虑，您可能倾向于使用 volatile 变量而不是锁。当使用 volatile 变量而非锁时，某些习惯用法（idiom）更加易于编码和阅读。此外，volatile 变量不会像锁那样造成线程阻塞，因此也很少造成可伸缩性问题。在某些情况下，如果读操作远远大于写操作，volatile 变量还可以提供优于锁的性能优势。 要使 volatile 变量提供理想的线程安全，必须同时满足下面两个条件： 1.对变量的写操作不依赖于当前值。 2.该变量没有包含在具有其他变量的不变式中。 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 第一个条件的限制使 volatile 变量不能用作线程安全计数器。虽然增量操作（x++）看上去类似一个单独操作，实际上它是一个由读取－修改－写入操作序列组成的组合操作，必须以原子方式执行，而 volatile 不能提供必须的原子特性。实现正确的操作需要使 x 的值在操作期间保持不变，而 volatile 变量无法实现这点。（然而，如果将值调整为只从单个线程写入，那么可以忽略第一个条件。） 大多数编程情形都会与这两个条件的其中之一冲突，使得 volatile 变量不能像 synchronized 那样普遍适用于实现线程安全。清单 1 显示了一个非线程安全的数值范围类。它包含了一个不变式 —— 下界总是小于或等于上界。 所以，还是离volatile远点吧，要始终牢记使用 volatile 的限制 —— 只有在状态真正独立于程序内其他内容时才能使用 volatile。 贴一段我的测试代码 @Test public void setSynchronizedValue() { final Jedis superjedis = getJedis(); superjedis.set(&quot;age&quot;, &quot;1&quot;); for (int i = 0; i &lt; 50; i++) { new Thread(new Runnable() { Jedis jedis = getJedis(); @Override public void run() { System.out.println(jedis.incr(&quot;age&quot;)); } }).start(); } } @Test public void setNormalValue() { for (int i = 0; i &lt; 50; i++) { new Thread(new Runnable() { @Override public void run() { // TODO Auto-generated method stub int currAge = age; // age 使用volatile static全局定义 System.out.println(++ currAge); testInt = currAge; } }).start(); } } 运行后可以看出，程序运行的结果是不确定的，这说明了++ currAge并不是原子级别的操作。 原因是声明为volatile的变量若与自身相关，如以下的声明方式：n=n+1,n++等，那么声明为volatile的变量就不起作用，也就是说关键字volatile无效。","tags":[{"name":"redis","slug":"redis","permalink":"http://yzy755.github.io/tags/redis/"},{"name":"线程安全","slug":"线程安全","permalink":"http://yzy755.github.io/tags/线程安全/"}]},{"title":"redis启动错误","date":"2017-04-18T03:11:36.000Z","path":"2017/04/18/redis启动错误/","text":"Creating Server TCP listening socket *:6379: bind:Unknown error今天遇到的问题，摘抄下网上的解决方案按顺序输入如下命令就可以连接成功 redis-cli.exe shutdown exit redis-server.exe redis.windows.conf","tags":[{"name":"redis","slug":"redis","permalink":"http://yzy755.github.io/tags/redis/"}]},{"title":"第三方快捷登录开发后对oauth的认识","date":"2017-04-13T06:17:53.000Z","path":"2017/04/13/第三方快捷登录开发后对oauth的认识/","text":"公司用户中心系统不仅需要传统的注册登录，主流的快捷登录肯定也必不可少，第三方快捷登录的流程和相应系统数据表的设计就先不记录了，主要摘抄一下网上对oauth的介绍和自己的理解OAuth是一个关于授权（authorization）的开放网络标准—-&gt;open authorization 应用场景： 有一个”云冲印”的网站，可以将用户储存在Google的照片，冲印出来。用户为了使用该服务，必须让”云冲印”读取自己储存在Google上的照片。 问题是只有得到用户的授权，Google才会同意”云冲印”读取这些照片。那么，”云冲印”怎样获得用户的授权呢？传统方法是，用户将自己的Google用户名和密码，告诉”云冲印”，后者就可以读取用户的照片了。这样的做法有以下几个严重的缺点。（1）”云冲印”为了后续的服务，会保存用户的密码，这样很不安全。（2）Google不得不部署密码登录，而我们知道，单纯的密码登录并不安全。（3）”云冲印”拥有了获取用户储存在Google所有资料的权力，用户没法限制”云冲印”获得授权的范围和有效期。（4）用户只有修改密码，才能收回赋予”云冲印”的权力。但是这样做，会使得其他所有获得用户授权的第三方应用程序全部失效。（5）只要有一个第三方应用程序被破解，就会导致用户密码泄漏，以及所有被密码保护的数据泄漏。OAuth就是为了解决上面这些问题而诞生的。原理：OAuth在”客户端”与”服务提供商”之间，设置了一个授权层（authorization layer）。”客户端”不能直接登录”服务提供商”，只能登录授权层，以此将用户与客户端区分开来。”客户端”登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。“客户端”登录授权层以后，”服务提供商”根据令牌的权限范围和有效期，向”客户端”开放用户储存的资料。 客户端的授权模式客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。OAuth 2.0定义了四种授权方式。授权码模式（authorization code）简化模式（implicit）密码模式（resource owner password credentials）客户端模式（client credentials） 授权码模式授权码模式（authorization code）是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与”服务提供商”的认证服务器进行互动。令牌对访问者是不可见的，后台是由httpclient获取令牌和所需信息的。 （A）用户访问客户端，后者将前者导向认证服务器。（B）用户选择是否给予客户端授权。（C）假设用户给予授权，认证服务器将用户导向客户端事先指定的”重定向URI”（redirection URI），同时附上一个授权码。（D）客户端收到授权码，附上早先的”重定向URI”，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。（E）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。…… A步骤中，客户端申请认证的URI，包含以下参数：response_type：表示授权类型，必选项，此处的值固定为”code”client_id：表示客户端的ID，必选项redirect_uri：表示重定向URI，必选项scope：表示申请的权限范围，可选项state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。示例url：http://openapi.qzone.qq.com/oauth/show?which=Login&amp;display=pc&amp;response_type=code&amp;client_id=101188868&amp;redirect_uri=account.booway.com.cn&amp;state=qqdenglu__http://yun.booway.com.cn/index.xhtml&amp;scope=get_user_info,get_info,add_t%20del_t%20add_pic_t,get_repost_list,get_other_info%20get_fanslist,get_idollist%20add_idol%20del_idolC步骤中，服务器回应客户端的URI，包含以下参数：code：表示授权码，必选项。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系。state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。D步骤中，客户端向认证服务器申请令牌的HTTP请求，包含以下参数：grant_type：表示使用的授权模式，必选项，此处的值固定为”authorization_code”。code：表示上一步获得的授权码，必选项。redirect_uri：表示重定向URI，必选项，且必须与A步骤中的该参数值保持一致。client_id：表示客户端ID，必选项。E步骤中，认证服务器发送的HTTP回复，包含以下参数：access_token：表示访问令牌，必选项。token_type：表示令牌类型，该值大小写不敏感，必选项，可以是bearer类型或mac类型。expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。refresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。云计算应用实例：QQ第三方登录 简化模式简化模式（implicit grant type）不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了”授权码”这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。 步骤如下：（A）客户端将用户导向认证服务器。（B）用户决定是否给于客户端授权。（C）假设用户给予授权，认证服务器将用户导向客户端指定的”重定向URI”，并在URI的Hash部分包含了访问令牌。（D）浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。（E）资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。（F）浏览器执行上一步获得的脚本，提取出令牌。（G）浏览器将令牌发给客户端。A步骤中，客户端发出的HTTP请求，包含以下参数：response_type：表示授权类型，此处的值固定为”token”，必选项。client_id：表示客户端的ID，必选项。redirect_uri：表示重定向的URI，必选项。scope：表示权限范围，可选项。state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。示例url：localhost:8080/booway_uums/openapi/oauth2/authorize-implicit?client_id=123&amp;response_type=token&amp;redirect_uri=oobC步骤中，认证服务器回应客户端的URI，包含以下参数：access_token：表示访问令牌，必选项。token_type：表示令牌类型，该值大小写不敏感，必选项。可以是bearer类型或mac类型。expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。示例url：http://localhost:8080/booway_uums/index/success.html#access_token=cb1617c64f1d6c2937c64b3599f2dd2&amp;state=null&amp;token_type=bearer&amp;expires_in=604800000&amp;scope=readCalendar Access Token 类型介绍OAuth2.0支持Bearer和MAC两种类型的Access Token。其中MAC类型只适用于API2.0接口：Bearer 介绍优点：调用简单，不需要对请求进行签名。缺点：请求API需要使用https协议保证信息传输安全。Access Token有效期一个月，过期后需要使用Refresh Token进行刷新。MAC 介绍优点：不依赖https协议，无协议加密带来的性能开销。Access Token长期有效，无需使用Refresh Token刷新。缺点：需要进行MAC计算。默认情况下，会获得Bearer类型的Access Token。如果开发者想要获得MAC类型的Access Token，需要在获取token时指定’token_type’参数为’mac’。 MAC计算标准化字符串标准化的请求字符串，就是用指定的请求属性按照某个规则拼接而成的字符串。在这里，其实标准化请求字符串，就是将 时间戳 + 随机码 + http方法 + uri + 主机 + 端口 + 其他参数的请求参数，以换行符(即：\\n)为连接符，合并起来得到的字符串。即使不需要其他参数也请在最后增加\\n。 如果用户访问的时候，客户端的”访问令牌”已经过期，则需要使用”更新令牌”申请一个新的访问令牌。客户端发出更新令牌的HTTP请求，包含以下参数：granttype：表示使用的授权模式，此处的值固定为”refreshtoken”，必选项。refresh_token：表示早前收到的更新令牌，必选项。scope：表示申请的授权范围，不可以超出上一次申请的范围，如果省略该参数，则表示与上一次一致。 计算expires_in到期时间的方法：7776000long longTime = System.currentTimeMillis() + Long.parseLong(“604800000”) * 1000; System.out.println(longTime); Date date = new Date(longTime); System.out.println(date); 密码模式密码模式（Resource Owner Password Credentials Grant）中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向”服务商提供商”索要授权。在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分，或者由一个著名公司出品。而认证服务器只有在其他授权模式无法执行的情况下，才能考虑使用这种模式。客户端模式客户端模式（Client Credentials Grant）指客户端以自己的名义，而不是以用户的名义，向”服务提供商”进行认证。严格地说，客户端模式并不属于OAuth框架所要解决的问题。在这种模式中，用户直接向客户端注册，客户端以自己的名义要求”服务提供商”提供服务，其实不存在授权问题。 搭建OAuth框架：Spring Security for OAuth ?Apis Authorization ServerRestlet FrameworkApache CXF Shiro oauth?? 一个OAuth2.0服务器端的实现 数据库简单设计:(可以不用数据库,access_token是临时的,放在内存中即可) create table access_token (id bigint,access_token varchar(255) NOT NULL,token_type varchar(255),expires varchar(255),refresh_token varchar(255),username varchar(255),client_id varchar(255),createdtime datetime,modifiedtime datetime); create table user (uid bigint,username varchar(255) NOT NULL,password varchar(255) NOT NULL); create table client (id bigint,client_id varchar(255) NOT NULL,client_secret varchar(255)); OAuth2.0协议主要是用access_token代替密码.授权服务器保管用户密码并向第三方应用发放access_token,第三方应用接触不到用户的密码.资源服务器保管需要授权才能访问的资源(其实就是服务器提供的API),第三方应用凭access_token访问资源服务器.(资源服务器还要问一下授权服务器这个access_token是不是真的) 授权服务器做两件事: 发放access_token的servlet 向资源服务器提供一个验证access_token真伪的WebService 四种获取access token的方式1 “Authorization Code” Grant2 “Implicit” Grant3 “Resource Owner Password Credentials” Grant4 “Client Credentials” Grant Refreshing an Access Token (在第一种方式里面要分两步获取access_token.) class TokenServlet extends HttpServlet{ void doGet() { String response_type = request.getParameter(“response_type”); if (response_type.equals(“token”)) { // TODO 第二种:”Implicit方式”; } } void doPost() { // TODO Filter Authorization: Basic base64(appkey:appsecret) // 验证 appkey appsecret String grant_type = request.getParameter(&quot;grant_type&quot;); if (grant_type.equals(&quot;authorization_code&quot;)) { // TODO 第一种:&quot;Authorization Code方式&quot;; return ; } if (grant_type.equals(&quot;password&quot;)) { // TODO 第三种:&quot;Password方式&quot;; return ; } if (grant_type.equals(&quot;client_credentials&quot;)) { // TODO 第四种:&quot;Client Credentials方式&quot;; return ; } if (grant_type.equals(&quot;refresh_token&quot;)) { // TODO 第五种:&quot;RefreshToken方式&quot;; return ; } } } OAuth2.0存在的安全问题： 场景一：见demo—-&gt;访问信任页面A，授权后产生cookie，在未退出或者未关闭浏览器的情况下携带A页面的cookie访问危险网站BB站中要求访问页面A，A并不知道这是用户的请求还是跨站请求所以会同意访问，B达到了模拟用户操作的目的。 场景二：通过Authorization code方式绑定QQ账号（1）用户甲到第三方网站A登录后，到了绑定页面。此时还没绑定微博。（2）绑定页面提供一个按钮：“绑定QQ”（地址a：http://aaa.com/index.xhtml?m=user_3rd_bind_qq）（3）用户甲点击地址a，程序生成如下地址b：https://api.weibo.com/oauth2/authorize?client_id=【9999999】&amp;redirect_uri=【http://aaa.comindex.xhtml?m=user_3rd_bind_qq_callback】&amp;response_type=【code】（4）用户甲浏览器定向到地址b，授权该应用。（5）授权服务器根据传递的redirect_uri参数，组合认证参数code生成地址c：http://aaa.comindex.xhtml?m=user_3rd_bind_qq_callback&amp;code=【809ui0asduve】（6）用户甲浏览器返回到地址c，完成绑定。第5步中返回地址所带的code 与当前用户的关系。。。两用户同时进行QQ绑定若没有各自特定的标识参数的后果。。。可以在第五步做手脚交换二者的code 就可以形成交叉绑定 state: RECOMMENDED. An opaque value used by the client to maintain state between the request and callback. The authorization server includes this value when redirecting the user-agent back to the client. The parameter SHOULD be used for preventing cross-site request forgery as described in Section 10.12. 使用state参数用于请求阶段和回调阶段之间的状态保持可防止CSRF攻击和防止错误绑定记录请求之前state，返回后比对—–&gt;安全返回的state只能匹配固定几种url头部才通过验证—–&gt;方便 Spring Security for OAuth 是针对OAuth2基于Security 的实现，token存放于内存 Shiro的1.2版本提供接入oauth2，实现可以用Apache Oltu，有整合资料 Apache Oltu是OAuth协议的Java语言实现。现在实现了oauth2.0标准的Java版本有：1、Spring Security for OAuth2、Apache Oltu(Apache Amber)3、Apis Authorization Server4、Restlet Framework5、Apache CXF","tags":[{"name":"第三方快捷登录","slug":"第三方快捷登录","permalink":"http://yzy755.github.io/tags/第三方快捷登录/"},{"name":"oauth2.0","slug":"oauth2-0","permalink":"http://yzy755.github.io/tags/oauth2-0/"}]},{"title":"基于shiro拓展并发登录人数控制","date":"2017-04-11T09:17:53.000Z","path":"2017/04/11/基于shiro拓展并发登录人数控制/","text":"在公司做了个视频网站，当然视频是需要购买的，就像爱奇艺那样，所以同一用户就要有一个客户端登录个数的控制，不然一个用户买了，能让一个公司的人看- -！spring security就直接提供了相应的功能；我的项目使用的权限框架是apach的shiro，Shiro的话没有提供默认实现，不过可以很容易的在Shiro中加入这个功能我们来看下shiro拦截机制中filter的关系图这里只介绍AccessControlFilter： AccessControlFilter提供了访问控制的基础功能；比如是否允许访问/当访问拒绝时如何处理等： abstract boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception; boolean onAccessDenied(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception; abstract boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception; isAccessAllowed：表示是否允许访问；mappedValue就是[urls]配置中拦截器参数部分，如果允许访问返回true，否则false； onAccessDenied：表示当访问拒绝时是否已经处理了；如果返回true表示需要继续处理；如果返回false表示该拦截器实例已经处理了，将直接返回即可。 onPreHandle会自动调用这两个方法决定是否继续处理： boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception { return isAccessAllowed(request, response, mappedValue) || onAccessDenied(request, response, mappedValue); } 另外AccessControlFilter还提供了如下方法用于处理如登录成功后/重定向到上一个请求： void setLoginUrl(String loginUrl) //身份验证时使用，默认/login.jsp String getLoginUrl() Subject getSubject(ServletRequest request, ServletResponse response) //获取Subject实例 boolean isLoginRequest(ServletRequest request, ServletResponse response)//当前请求是否是登录请求 void saveRequestAndRedirectToLogin(ServletRequest request, ServletResponse response) throws IOException //将当前请求保存起来并重定向到登录页面 void saveRequest(ServletRequest request) //将请求保存起来，如登录成功后再重定向回该请求 void redirectToLogin(ServletRequest request, ServletResponse response) //重定向到登录页面 比如基于表单的身份验证就需要使用这些功能。 如果我们想进行访问访问的控制就可以继承AccessControlFilter；如果我们要添加一些通用数据我们可以直接继承PathMatchingFilter。所以定义一个类继承AccessControlFilter重写onAccessDenied方法，isAccessAllowed方法直接返回false，使程序进入拒绝访问的处理过程，也就是onAccessDenied方法，在这个方法中，我们的思路就是 1.使用链表记录同一用户的登录sessionid，用shiro提供的cache记录用户和session的映射关系，用户名为key,链表为value 2.用户登录后使用subject拿到用户名，以用户名取出当前服务器存储的sessionid链表，判断链表中有无当前登录的sessionid，无则push 3.判断链表的的长度，若大于系统允许的登录数，链表进行移除操作，获得移除的session并标记为被踢出（移除的顺序可配置为踢前者或者后者） 4.被移除的session（客户端）再次访问系统页面时，走完上述过程发现自己有被踢出的标记，调用subject.logout()方法，并重定向到踢出的提示页面帖一波代码： public class KickoutSessionControlFilter extends AccessControlFilter { private Logger logger = LoggerFactory.getLogger(KickoutSessionControlFilter.class); private String kickoutUrl; // 踢出后到的地址 private boolean kickoutAfter; // 踢出之前登录的或之后登录的用户 (在配置文件中配) private int maxSession = 1; // 同一个帐号最大会话数 默认1 private SessionManager sessionManager; private Cache&lt;String, Deque&lt;Serializable&gt;&gt; cache; @Override protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception { return false; } @Override protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception { Subject subject = getSubject(request, response); if (!subject.isAuthenticated() &amp;&amp; !subject.isRemembered()) { // 如果没有登录，直接进行之后的流程 return true; } Session session = subject.getSession(); String username = (String) subject.getPrincipal(); Serializable sessionId = session.getId(); // 同步控制 Deque&lt;Serializable&gt; deque = cache.get(username); if (deque == null) { deque = new LinkedList&lt;Serializable&gt;(); } // 如果队列里没有此sessionId，且用户没有被踢出；放入队列 if (!deque.contains(sessionId) &amp;&amp; session.getAttribute(&quot;kickout&quot;) == null) { deque.push(sessionId); } // 如果队列里的sessionId数超出最大会话数，开始踢人 while (deque.size() &gt; maxSession) { Serializable kickoutSessionId = null; if (kickoutAfter) { // 如果踢出后者 kickoutSessionId = deque.removeFirst(); } else { // 否则踢出前者 kickoutSessionId = deque.removeLast(); } try { Session kickoutSession = sessionManager.getSession(new DefaultSessionKey(kickoutSessionId)); if (kickoutSession != null) { // 设置会话的kickout属性表示踢出了 kickoutSession.setAttribute(&quot;kickout&quot;, true); } } catch (Exception e) { e.printStackTrace(); logger.error(e.getMessage(), e); } } cache.put(username, deque); // 如果被踢出了，直接退出，重定向到踢出后的地址 if (session.getAttribute(&quot;kickout&quot;) != null) { try { subject.logout(); } catch (Exception e) { e.printStackTrace(); logger.error(e.getMessage(), e); } saveRequest(request); WebUtils.issueRedirect(request, response, kickoutUrl); return false; } return true; } public void setKickoutUrl(String kickoutUrl) { this.kickoutUrl = kickoutUrl; } public void setKickoutAfter(boolean kickoutAfter) { this.kickoutAfter = kickoutAfter; } public void setMaxSession(int maxSession) { this.maxSession = maxSession; } public void setSessionManager(SessionManager sessionManager) { this.sessionManager = sessionManager; } public void setCacheManager(CacheManager cacheManager) { this.cache = cacheManager.getCache(&quot;shiro-kickout-session&quot;); } } 当然上述的实现离不开shiro的正确配置，帖一波配置： &lt;bean id=&quot;securityManager&quot; class=&quot;org.apache.shiro.web.mgt.DefaultWebSecurityManager&quot;&gt; &lt;property name=&quot;realms&quot;&gt; &lt;util:list id=&quot;beanList&quot;&gt; &lt;ref bean=&quot;myCasRealm&quot; /&gt; &lt;ref bean=&quot;myLoginRealm&quot; /&gt; &lt;/util:list&gt; &lt;/property&gt; &lt;!-- &lt;property name=&quot;realm&quot; ref=&quot;myCasRealm&quot; /&gt; --&gt; &lt;property name=&quot;subjectFactory&quot; ref=&quot;casSubjectFactory&quot; /&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;cacheManager&quot; /&gt; &lt;property name=&quot;sessionManager&quot; ref=&quot;sessionManager&quot; /&gt; &lt;/bean&gt; &lt;!-- 如果要实现cas的remember me的功能，需要用到下面这个bean，并设置到securityManager的subjectFactory中 --&gt; &lt;bean id=&quot;casSubjectFactory&quot; class=&quot;org.apache.shiro.cas.CasSubjectFactory&quot; /&gt; &lt;!-- 項目自定义的Realm --&gt; &lt;bean id=&quot;myCasRealm&quot; class=&quot;com.booway.shiro.MyCasRealm&quot;&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;cacheManager&quot; /&gt; &lt;property name=&quot;casServerUrlPrefix&quot; value=&quot;${cas.server.url}&quot; /&gt; &lt;!-- 客户端的回调地址设置，必须和下面的shiro-cas过滤器拦截的地址一致 --&gt; &lt;property name=&quot;casService&quot; value=&quot;/cas&quot; /&gt; &lt;/bean&gt; &lt;!-- 項目自定义的Realm --&gt; &lt;bean id=&quot;myLoginRealm&quot; class=&quot;com.booway.shiro.MyLoginRealm&quot;&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;cacheManager&quot; /&gt; &lt;property name=&quot;casServerUrlPrefix&quot; value=&quot;${cas.server.url}&quot; /&gt; &lt;!-- 客户端的回调地址设置，必须和下面的shiro-cas过滤器拦截的地址一致 --&gt; &lt;property name=&quot;casService&quot; value=&quot;/cas&quot; /&gt; &lt;/bean&gt; &lt;!-- 用户授权信息Cache --&gt; &lt;bean id=&quot;cacheManager&quot; class=&quot;org.apache.shiro.cache.MemoryConstrainedCacheManager&quot; /&gt; &lt;!-- 会话ID生成器 --&gt; &lt;bean id=&quot;sessionIdGenerator&quot; class=&quot;org.apache.shiro.session.mgt.eis.JavaUuidSessionIdGenerator&quot;/&gt; &lt;!-- 会话DAO --&gt; &lt;bean id=&quot;sessionDAO&quot; class=&quot;org.apache.shiro.session.mgt.eis.EnterpriseCacheSessionDAO&quot;&gt; &lt;property name=&quot;activeSessionsCacheName&quot; value=&quot;shiro-activeSessionCache&quot;/&gt; &lt;property name=&quot;sessionIdGenerator&quot; ref=&quot;sessionIdGenerator&quot;/&gt; &lt;/bean&gt; &lt;!-- 会话Cookie模板 --&gt; &lt;bean id=&quot;sessionIdCookie&quot; class=&quot;org.apache.shiro.web.servlet.SimpleCookie&quot;&gt; &lt;constructor-arg value=&quot;sid&quot;/&gt; &lt;property name=&quot;httpOnly&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;maxAge&quot; value=&quot;3600&quot;/&gt; &lt;/bean&gt; &lt;!-- 会话管理器 --&gt; &lt;bean id=&quot;sessionManager&quot; class=&quot;org.apache.shiro.web.session.mgt.DefaultWebSessionManager&quot;&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;cacheManager&quot; /&gt; &lt;property name=&quot;globalSessionTimeout&quot; value=&quot;1800000&quot;/&gt; &lt;property name=&quot;deleteInvalidSessions&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;sessionValidationSchedulerEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;sessionValidationScheduler&quot; ref=&quot;sessionValidationScheduler&quot;/&gt; &lt;property name=&quot;sessionDAO&quot; ref=&quot;sessionDAO&quot;/&gt; &lt;property name=&quot;sessionIdCookieEnabled&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;sessionIdCookie&quot; ref=&quot;sessionIdCookie&quot;/&gt; &lt;/bean&gt; &lt;!-- 会话验证调度器 --&gt; &lt;bean id=&quot;sessionValidationScheduler&quot; class=&quot;org.apache.shiro.session.mgt.quartz.QuartzSessionValidationScheduler&quot;&gt; &lt;property name=&quot;sessionValidationInterval&quot; value=&quot;1800000&quot;/&gt; &lt;property name=&quot;sessionManager&quot; ref=&quot;sessionManager&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;kickoutSessionControlFilter&quot; class=&quot;com.booway.shiro.KickoutSessionControlFilter&quot;&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;cacheManager&quot; /&gt; &lt;property name=&quot;sessionManager&quot; ref=&quot;sessionManager&quot; /&gt; &lt;property name=&quot;kickoutAfter&quot; value=&quot;false&quot; /&gt; &lt;property name=&quot;maxSession&quot; value=&quot;1&quot; /&gt; &lt;property name=&quot;kickoutUrl&quot; value=&quot;/kickout.xhtml&quot; /&gt; &lt;/bean&gt; &lt;!-- Shiro Filter --&gt; &lt;bean id=&quot;shiroFilter&quot; class=&quot;com.booway.shiro.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot; /&gt; &lt;!-- 用于调用Controller --&gt; &lt;property name=&quot;service&quot; value=&quot;${uam.login.failurl}&quot; /&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;${cas.server.login.url}?service=&quot; /&gt; &lt;!-- 用户访问未授权页面后跳转的错误信息页面 --&gt; &lt;property name=&quot;unauthorizedUrl&quot; value=&quot;/401.html&quot;&gt;&lt;/property&gt; &lt;!-- 自己实现的formAuthcFilter，加入key type --&gt; &lt;property name=&quot;filters&quot;&gt; &lt;util:map&gt; &lt;entry key=&quot;casFilter&quot; value-ref=&quot;casFilter&quot;&gt; &lt;/entry&gt; &lt;entry key=&quot;singleSignOutFilter&quot; value-ref=&quot;singleSignOutFilter&quot;&gt; &lt;/entry&gt; &lt;entry key=&quot;roles&quot; value-ref=&quot;roleFilter&quot;&gt; &lt;/entry&gt; &lt;entry key=&quot;kickout&quot; value-ref=&quot;kickoutSessionControlFilter&quot;&gt; &lt;/entry&gt; &lt;/util:map&gt; &lt;/property&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; /** = singleSignOutFilter,casFilter,kickout &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;casFilter&quot; class=&quot;com.booway.shiro.MyCasFilter&quot;&gt; &lt;!-- 配置验证错误时的失败页面 --&gt; &lt;property name=&quot;failureUrl&quot; value=&quot;${uam.login.failurl}&quot; /&gt; &lt;property name=&quot;successUrl&quot; value=&quot;/index.xhtml&quot; /&gt; &lt;property name=&quot;casLoginUrl&quot; value=&quot;${cas.server.login.url}&quot; /&gt; &lt;property name=&quot;interceptUrlPrefix&quot;&gt; &lt;list&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=&quot;loginUrls&quot;&gt; &lt;list&gt; &lt;value&gt;/index/login.xhtml&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- &lt;property name=&quot;excludeUrls&quot;&gt; &lt;list&gt; &lt;value&gt;/index.xhtml&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; --&gt; &lt;/bean&gt; &lt;bean id=&quot;userFilter&quot; class=&quot;com.booway.shiro.MyUserFilter&quot;&gt; &lt;!-- 配置验证错误时的失败页面 --&gt; &lt;property name=&quot;failureUrl&quot; value=&quot;${uam.login.failurl}&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;logoutFilter&quot; class=&quot;com.booway.shiro.MyLogoutFilter&quot;&gt; &lt;/bean&gt; &lt;bean id=&quot;roleFilter&quot; class=&quot;com.booway.shiro.RolesAuthorizationFilter&quot;&gt; &lt;/bean&gt; &lt;!-- 退出过滤器 --&gt; &lt;bean id=&quot;singleSignOutFilter&quot; class=&quot;com.booway.shiro.CustomSingleSignOutFilter&quot;&gt; &lt;/bean&gt; &lt;!-- 保证实现了Shiro内部lifecycle函数的bean执行 --&gt; &lt;bean id=&quot;lifecycleBeanPostProcessor&quot; class=&quot;org.apache.shiro.spring.LifecycleBeanPostProcessor&quot; /&gt; &lt;!-- AOP式方法级权限检查 --&gt; &lt;bean class=&quot;org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator&quot; depends-on=&quot;lifecycleBeanPostProcessor&quot;&gt; &lt;property name=&quot;proxyTargetClass&quot; value=&quot;true&quot; /&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.beans.factory.config.MethodInvokingFactoryBean&quot;&gt; &lt;property name=&quot;staticMethod&quot; value=&quot;org.apache.shiro.SecurityUtils.setSecurityManager&quot; /&gt; &lt;property name=&quot;arguments&quot; ref=&quot;securityManager&quot; /&gt; &lt;/bean&gt; &lt;!-- 开启Shiro的注解(如@RequiresRoles,@RequiresPermissions), 需借助SpringAOP扫描使用Shiro注解的类,并在必要时进行安全逻辑验证 --&gt; &lt;bean class=&quot;org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot; /&gt; &lt;/bean&gt; 这样一个shiro的拓展就完成啦！","tags":[{"name":"shiro","slug":"shiro","permalink":"http://yzy755.github.io/tags/shiro/"}]},{"title":"jvm内存分配","date":"2017-03-24T07:56:48.000Z","path":"2017/03/24/jvm内存分配/","text":"java内存组成介绍：堆(Heap)和非堆(Non-heap)内存 按照官方的说法：“Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的。”“在JVM中堆之外的内存称为非堆内存(Non-heap memory)”。可以看出JVM主要管理两种类型的内存：堆和非堆。简单来说堆就是Java代码可及的内存，是留给开发人员使用的；非堆就是JVM留给 自己用的，所以方法区、JVM内部处理或优化所需的内存(如JIT编译后的代码缓存)、每个类结构(如运行时常数池、字段和方法数据)以及方法和构造方法 的代码都在非堆内存中。 方法栈&amp;本地方法栈: 线程创建时产生,方法执行时生成栈帧 方法区 存储类的元数据信息 常量等 堆 java代码中所有的new操作 native Memory(C heap) Direct Bytebuffer JNI Compile GC; 堆内存分配 JVM初始分配的内存由-Xms指定，默认是物理内存的1/64；JVM最大分配的内存由-Xmx指 定，默认是物理内存的1/4。默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制；空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制。因此服务器一般设置-Xms、-Xmx相等以避免在每次GC 后调整堆的大小。对象的堆内存由称为垃圾回收器的自动内存管理系统回收。 组成 详解 Young Generation 即图中的Eden + From Space + To Space Eden 存放新生的对象 Survivor Space 有两个，存放每次垃圾回收后存活的对象 Old Generation Tenured Generation 即图中的Old Space 主要存放应用程序中生命周期长的存活对象 非堆内存分配 JVM使用-XX:PermSize设置非堆内存初始值，默认是物理内存的1/64；由XX:MaxPermSize设置最大非堆内存的大小，默认是物理内存的1/4。 组成 详解 Permanent Generation 保存虚拟机自己的静态(refective)数据 主要存放加载的Class类级别静态对象如class本身，method，field等等 permanent generation空间不足会引发full GC(详见HotSpot VM GC种类) Code Cache 用于编译和保存本地代码（native code）的内存 JVM内部处理或优化 JVM内存限制(最大值) JVM内存的最大值跟操作系统有很大的关系。简单的说就32位处理器虽然 可控内存空间有4GB,但是具体的操作系统会给一个限制，这个限制一般是2GB-3GB（一般来说Windows系统下为1.5G-2G，Linux系统 下为2G-3G），而64bit以上的处理器就不会有限制了。","tags":[{"name":"jvm","slug":"jvm","permalink":"http://yzy755.github.io/tags/jvm/"},{"name":"内存分配","slug":"内存分配","permalink":"http://yzy755.github.io/tags/内存分配/"}]},{"title":"linux环境下ffmpeg加入libx264编译方法","date":"2017-03-10T08:50:48.000Z","path":"2017/03/10/linux环境下ffmpeg加入libx264编译方法/","text":"下载源码 libx264 http://download.videolan.org/x264/snapshots/ 最新版 yasm http://yasm.tortall.net/Download.html 版本为yasm-1.3.0(yasm是汇编编译器,因为ffmpeg中为了提高效率用到了汇编指令) ffmpeg http://www.ffmpeg.org/download.html 版本为ffmpge-2.6.3编译 yasm解压yasm-1.3.0至当前目录tar -zxvf yasm.1.3.0.tar.gzcd yasm./configure –prefix=/usr/local/yasmmakemake install libx264解压x264-snapshot-20140424-2245.tar至当前目录tar -zxvf x264-snapshot-20140424-2245.tarcd x264./configure –prefix=/usr/local/x264 –enable-shared –enable-static –enable-yasmmakemake install ffmpeg解压ffmpeg-2.8.0.tar至当前目录tar -zxvf ffmpeg-2.8.0.tarcd ffmpeg./configure –prefix=/usr/local/ffmpeg –enable-shared –enable-libx264 –enable-gpl –enable-pthreads –extra-cflags=-I/usr/local/x264/include –extra-ldflags=-L/usr/local/x264/libmakemake install容易出现的问题error while loading shared libraries: libpostproc.so.53（libx264.so.148）: cannot open shared object file: No such file or directory运行 ldd $(which ffmpeg) 命令 ps:ldd命令用于判断某个可执行的 binary 档案含有什么动态函式库在linux下安装ffmpeg出现此问题运行改命令示例：linux-vdso.so.1 =&gt; (0x00007fff6173b000) libavdevice.so.56 =&gt; /usr/local/ffmpeg/lib/libavdevice.so.56 (0x00007f61761fc000) libavfilter.so.5 =&gt; /usr/local/ffmpeg/lib/libavfilter.so.5 (0x00007f6175e70000) libavformat.so.56 =&gt; /usr/local/ffmpeg/lib/libavformat.so.56 (0x00007f6175a8c000) libavcodec.so.56 =&gt; /usr/local/ffmpeg/lib/libavcodec.so.56 (0x00007f61745eb000) libpostproc.so.53 =&gt; not found libswresample.so.1 =&gt; /usr/local/ffmpeg/lib/libswresample.so.1 (0x00007f61743cf000) libswscale.so.3 =&gt; /usr/local/ffmpeg/lib/libswscale.so.3 (0x00007f617413e000) libavutil.so.54 =&gt; /usr/local/ffmpeg/lib/libavutil.so.54 (0x00007f6173ed7000) libm.so.6 =&gt; /lib64/libm.so.6 (0x00007f6173c52000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f6173a35000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f61736a1000) libpostproc.so.53 =&gt; not found libz.so.1 =&gt; /lib64/libz.so.1 (0x00007f617348a000) libx264.so.148 =&gt; not found librt.so.1 =&gt; /lib64/librt.so.1 (0x00007f6173281000) /lib64/ld-linux-x86-64.so.2 (0x00007f617641c000)可以看到libpostproc.so.53和libx264.so.148 not found出现这类错误表示，系统不知道xxx.so放在哪个目录下，这时候就要在/etc/ld.so.conf中加入xxx.so所在的目录。一般而言，有很多的so会存放在/usr/local/lib这个目录底下，去这个目录底下找，果然发现自己所需要的.so文件。所以，在/etc/ld.so.conf中加入/usr/local/lib这一行，保存之后，再运行：/sbin/ldconfig –v(或者直接运行ldconfig命令)更新一下配置即可。","tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"http://yzy755.github.io/tags/ffmpeg/"},{"name":"编译","slug":"编译","permalink":"http://yzy755.github.io/tags/编译/"}]},{"title":"hexo编辑博客整理","date":"2017-03-08T07:56:48.000Z","path":"2017/03/08/hexo编辑博客整理/","text":"一.Hexo搭建Github-Pages博客 1.安装nodejs和git,方法略 2.安装hexo $ npm install -g hexo 3.部署hexo $ hexo init . ├── .deploy ├── public ├── scaffolds ├── scripts ├── source | ├── _drafts | └── _posts ├── themes ├── _config.yml └── package.json .deploy：执行hexo deploy命令部署到GitHub上的内容目录 public：执行hexo generate命令，输出的静态网页内容目录 scaffolds：layout模板文件目录，其中的md文件可以添加编辑 scripts：扩展脚本目录，这里可以自定义一些javascript脚本 source：文章源码目录，该目录下的markdown和html文件均会被hexo处理。该页面对应repo的根目录，404文件、favicon.ico文件，CNAME文件等都应该放这里，该目录下可新建页面目录。 _drafts：草稿文章 _posts：发布文章 themes：主题文件目录 _config.yml：全局配置文件，大多数的设置都在这里 package.json：应用程序数据，指明hexo的版本等信息，类似于一般软件中的关于按钮 4.Hexo命令 Hexo下，通过 _config.yml 设置博客，可以想象成我们用的软件里的设置一样，只是它通过一个文件列出这些参数，然后让我们填写和修改。 全局设置 在你博客目录下有一个文件名_config.yml，打开可以配置信息。 局部页面 在你博客目录下 \\themes\\你使用的主题\\_config.yml 写博客相关命令 Hexo常用命令： hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server） hexo deploy #将.deploy目录部署到GitHub 当然，如果每次输入那么长命令，那么一定想到用简写： hexo n == hexo new hexo g == hexo generate hexo s == hexo server hexo d == hexo deploy 其它的，还可以复合命令： hexo deploy -g hexo server -g 有时候生成的网页出错了，而生成的rss其实没有清除，那么用下面的命令，在重新生成吧 $ hexo clean 当本地调试出现诡异现象时候，请先使用 hexo clean 清理已经生成的静态文件后重试。 注：Hexo原理就是hexo在执行hexo generate时会在本地先把博客生成的一套静态站点放到public文件夹中，在执行hexo deploy时将其复制到.deploy文件夹中。Github的版本库通常建议同时附上README.md说明文件，但是hexo默认情况下会把所有md文件解析成html文件，所以即使你在线生成了README.md，它也会在你下一次部署时被删去。怎么解决呢？ 在执行hexo deploy前把在本地写好的README.md文件复制到.deploy文件夹中，再去执行hexo deploy。 5.博客管理 上面命令中，其实生成文章，可以直接把写好的文章插入到目录/_posts 下面，后缀为.MD就行，在文章头部固定格式： title: Mac提高使用效率的一些方法 #文章的标题，这个才是显示的文章标题，其实文件名不影响 date: 2015-09-01 20:33:26 #用命令会自动生成，也可以自己写，所以文章时间可以改 categories: technology #文章的分类，这个可以自己定义 tags: [Mac,效率,快捷方式] #tag，为文章添加标签，方便搜索 --- 当然，里面有很多东西的，如果你专注于写作，那么可以不用太关心了，比如tags标签可以写成下面那样，因为hexo文章的头部文件是用AML来写的。 tags: - tag1 - tag2 如果在博客文章列表中，不想全文显示，可以增加 &lt;!--more--&gt;, 后面的内容就不会显示在列表。 &lt;!--more--&gt; 6.插件 安装插件 $ npm install &lt;plugin-name&gt; --save 添加RSS npm install hexo-generator-feed 然后，到博客目录 /public 下，如果没有发现atom.xml，说明命令没有生效！！！(楼主就是在这里被坑了次) 解决方法： $ npm install hexo-generator-feed --save 这个命令来自hexo-generator-feed Install $ npm install hexo-generator-feed --save Hexo 3: 1.x Hexo 2: 0.x Options You can configure this plugin in _config.yml. feed: type: atom path: atom.xml limit: 20 type - Feed type. (atom/rss2) path - Feed path. (Default: atom.xml/rss2.xml) limit - Maximum number of posts in the feed (Use 0 or false to show all posts) 其中可以选择： 然后在 Hexo 根目录下的 _config.yml 里配置一下 feed: type: atom path: atom.xml limit: 20 #type 表示类型, 是 atom 还是 rss2. #path 表示 Feed 路径 #limit 最多多少篇最近文章 最后，在 hexo generate之后，会发现public文件夹下多了atom.xml！ 例如要订阅我的blog只要输入ihtc.cc/atom就可以搜寻到啦！ 添加Sitemap Sitemap 的提交主要的目的，是要避免搜索引擎的爬虫没有完整的收录整个网页的内容，所以提交 Sitemap 是能够补足搜索引擎的不足，进而加速网页的收录速度，达到搜寻引擎友好的目的。 $ npm install hexo-generator-sitemap --save 这个命令来自hexo-generator-sitemap Install $ npm install hexo-generator-sitemap --save Hexo 3: 1.x Hexo 2: 0.x Options You can configure this plugin in _config.yml. sitemap: path: sitemap.xml path - Sitemap path. (Default: sitemap.xml) 同样可以选择： 在 Hexo 根目录下的 _config.yml 里配置一下 sitemap: path: sitemap.xml #path 表示 Sitemap 的路径. 默认为 sitemap.xml. 对于国内用户还需要安装插件 hexo-generator-baidu-sitemap, 顾名思义是为百度量身打造的. 安装 $ npm install hexo-generator-baidu-sitemap --save 然后在 Hexo 根目录下的 _config.yml 里配置一下 baidusitemap: path: baidusitemap.xml 为了博客有更好的展示率, 最好的方式是通过搜索引擎, 提交 Sitemap文件是一个方式，具体可参考： Hexo 优化与定制(二) | Kang Lu&apos;s Blog ｜Hexo优化｜如何向google提交sitemap（详细） | Fiona&apos;s Blog 其它插件 Plugins · hexojs/hexo 7.评论设置 在Hexo中，默认使用的评论是国外的Disqus,不过因为国内的”网络环境”问题，我们改为国内的多说评论系统。 需要说明的是 short_name:字段，这个字段为你多说填写的站点名字，比如我的域名：ihtcboy.duoshuo.com，那么我的short_name:&quot;ihtcboy&quot; 8.404页面 GitHub Pages 自定义404页面非常容易，直接在根目录下创建自己的404.html就可以。但是自定义404页面仅对绑定顶级域名的项目才起作用，GitHub默认分配的二级域名是不起作用的，使用hexo server在本机调试也是不起作用的。 其实，404页面可以做更多有意义的事，来做个404公益项目吧。 腾讯公益 404.html : &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;404&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;br&gt;&lt;!-- &lt;!DOCTYPE HTML&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;公益404 | 不如&lt;/title&gt; &lt;/head&gt; &lt;body&gt; #404 Not found By Bruce &lt;h1&gt;404 Page Not Found&lt;/h1&gt; --&gt;&lt;br&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;http://www.qq.com/404/search_children.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;br&gt;&lt;!-- 公益404介接入地址 益云公益404 http://yibo.iyiyun.com/Index/web404 腾讯公益404 http://www.qq.com/404 失蹤兒童少年資料管理中心404 http://404page.missingkids.org.tw --&gt; &lt;br&gt; &lt;/body&gt; &lt;/html&gt; 复制上面代码，贴粘到目录下新建的404.html即可！ 9.统计 因Google Analytics偶尔被墙，故国内用百度统计 最新的统计服务已经开放，两行代码轻松搞定，你可以直接使用：不蒜子 本人墙裂推荐，只需要两行代码哦。各种用法实例和显示效果参考不蒜子文档中的实例链接。不蒜子，极客的算子，极简的算子，任你发挥的算子。 10.更新 更新hexo： npm update -g hexo 更新主题： cd themes/你的主题 git pull 更新插件： npm update 11.在 hexo 中无痛使用本地图片 首先确认 _config.yml 中有 post_asset_folder:true 在 hexo 目录，执行 npm install https://github.com/CodeFalling/hexo-asset-image --save 假设在 MacGesture2-Publish ├── apppicker.jpg ├── logo.jpg └── rules.jpg MacGesture2-Publish.md 这样的目录结构（目录名和文章名一致），只要使用 ![logo](MacGesture2-Publish/logo.jpg) 就可以插入图片。 生成的结构为 public/2015/10/18/MacGesture2-Publish ├── apppicker.jpg ├── index.html ├── logo.jpg └── rules.jpg 同时，生成的 html 是 &lt;img src=&quot;/2015/10/18/MacGesture2-Publish/logo.jpg&quot; alt=&quot;logo&quot;&gt; 12.添加评论插件 在_config.yml中添加多说的配置： duoshuo_shortname: 你站点的short_name ps:只需要写你注册填写的内容 修改themes\\landscape\\layout\\_partial\\article.ejs模板 把 &lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.disqus_shortname){ %&gt; &lt;section id=&quot;comments&quot;&gt; &lt;div id=&quot;disqus_thread&quot;&gt; &lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&quot;//disqus.com/?ref_noscript&quot;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt; &lt;/div&gt; &lt;/section&gt; &lt;% } %&gt; 改为 &lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.duoshuo_shortname){ %&gt; &lt;section id=&quot;comments&quot;&gt; &lt;!-- 多说评论框 start --&gt; &lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;&lt;%= post.layout %&gt;-&lt;%= post.slug %&gt;&quot; data-title=&quot;&lt;%= post.title %&gt;&quot; data-url=&quot;&lt;%= page.permalink %&gt;&quot;&gt;&lt;/div&gt; &lt;!-- 多说评论框 end --&gt; &lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt; &lt;script type=&quot;text/javascript&quot;&gt; var duoshuoQuery = {short_name:&apos;&lt;%= config.duoshuo_shortname %&gt;&apos;}; (function() { var ds = document.createElement(&apos;script&apos;); ds.type = &apos;text/javascript&apos;;ds.async = true; ds.src = (document.location.protocol == &apos;https:&apos; ? &apos;https:&apos; : &apos;http:&apos;) + &apos;//static.duoshuo.com/embed.js&apos;; ds.charset = &apos;UTF-8&apos;; (document.getElementsByTagName(&apos;head&apos;)[0] || document.getElementsByTagName(&apos;body&apos;)[0]).appendChild(ds); })(); &lt;/script&gt; &lt;!-- 多说公共JS代码 end --&gt; &lt;/section&gt; &lt;% } %&gt;","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yzy755.github.io/tags/hexo/"}]},{"title":"zookeeper浅读","date":"2017-03-08T07:44:27.000Z","path":"2017/03/08/zookeeper浅读/","text":"下面我们来看下开源dubbo推荐的业界成熟的zookeeper做为注册中心， zookeeper是hadoop的一个子项目是分布式系统的可靠协调者，他提供了配置维护，名字服务，分布式同步等服务。对于zookeeper的原理本文档不分析，后面有时间在做专题。zookeeper注册中心Zookeeper对数据存储类似linux的目录结构，下面给出官方文档对dubbo注册数据的存储示例 假设读者对zookeeper有所了解，能够搭建zookeeper服务，其实不了解也没关系，谷歌百度下分分钟搞起。作为测试调试dubbo，我是在本地起的zookeeper 指定zookeeper配置文件地址 配置文件中两个关键参数：dataDir zookeeper存储文件的地址clientPort 客户端链接的端口号Dubbo服务提供者配置 除了配置注册中心的，其他都一样Dubbo服务消费者配置","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://yzy755.github.io/tags/zookeeper/"}]},{"title":"TCP的三次握手和四次挥手","date":"2017-03-08T03:48:05.000Z","path":"2017/03/08/TCP的三次握手和四次挥手/","text":"在TCP层，有个FLAGS字段，这个字段有以下几个标识：SYN, FIN, ACK, PSH, RST, URG. 其中，对于我们日常的分析有用的就是前面的五个字段。 它们的含义是： SYN表示建立连接，1表示发起， FIN表示关闭连接，1表示发起 ACK表示响应，1表示确认 PSH表示有 DATA数据传输， RST表示连接重置。 三次握手 第一次握手 客户端像服务端发送SYN=1,seq=n; 第二次握手 服务端接收到消息返回ACK=1,SYN=1,seq=m,ack=n+1; 第三次握手 客户端接到消息返回ACK=1,ack=m+1。 TCP采用三次握手建立连接如下图所示。 为什么不是两次，不是4次？假设经过前两次握手，此时在服务端的角度来看，服务端技能接收消息，也能发送消息，但是不知道发出去的消息能不能被客户端接收，经过第三次客户端的回应之后，双方都能保证自己既能接收消息，也能发送消息，所以第三次握手之后就建立了安全的连接。 为什么不是4次就很简单了，多了浪费。 四次握手 第一次挥手 客户端向服务端发送FIN=1,seq=n，表示准备好要断开连接了； 第二次挥手 服务端向客户端发送ACK=1,ack=n+1，表示收到了客户端要断开连接的消息了，但是此时需要等一等，需要将数据传输完毕（基于安全的考虑）； 第三次挥手 服务端向客户端发送FIN=1,seq=m，表示服务端这边也准备好可以断开连接了； 第四次挥手 客户端向服务端发送ACK=1,ack=m+1，表示收到了服务端断开的消息，就此分手。 TCP采用四次挥手关闭连接如下图所示。","tags":[{"name":"tcp","slug":"tcp","permalink":"http://yzy755.github.io/tags/tcp/"},{"name":"三次握手","slug":"三次握手","permalink":"http://yzy755.github.io/tags/三次握手/"},{"name":"四次挥手","slug":"四次挥手","permalink":"http://yzy755.github.io/tags/四次挥手/"}]},{"title":"微信小程序保存登录状态","date":"2017-03-05T09:17:53.000Z","path":"2017/03/05/微信小程序保存登录状态/","text":"浏览器能保证访问网站的session的唯一性是因为访问网站后服务器会分配session，sessionid会记录在浏览器的cookie中.小程序并没有这样的机制，所以当用户登陆后，小程序应保存sessionid，从而保证在发送请求时http头部携带sessionid保证用户的登录状态。服务器登录及后续请求流程： a)请求用户中心登录，校验用户名密码，返回账户实体 /openapi/accountService/login b)校验成功后保存账户实体，请求云课堂登录接口，使用shiro登录当前账号返回seesionid并在小程序端缓存，代码参考IndexController中的loginFragment方法。 c)登陆后请求受保护的资源在请求中加入http头部如下： header: { //‘Accept’: ‘application/json’, ‘Cookie’: ‘sid=’ + wx.getStorageSync(“session_id”) },","tags":[{"name":"微信小程序","slug":"微信小程序","permalink":"http://yzy755.github.io/tags/微信小程序/"},{"name":"session","slug":"session","permalink":"http://yzy755.github.io/tags/session/"}]},{"title":"jar包在windows下的运行命令","date":"2017-03-02T09:17:53.000Z","path":"2017/03/02/jar包在windows下运行命令/","text":"1、打jar包 jar -cvf xx.jar 文件夹名称 说明一下：.表示把当前目录下面以及子目录的所有class都打到这个xx.jar里。 -cvf的含义，可以自己去用jar命令去查看 如果要单独对某个或某些class文件进行打包，可以这样： jar -cvf xx.jar Foo.class Bar.class 2.运行jar java -jar xx.jar 要运行一个jar，则此jar内部的META-INF\\MANIFEST.MF文件里必须指明要执行的main方法类 具体格式如： Manifest-Version: 1.0Created-By: 1.6.0_03 (Sun Microsystems Inc.)Main-class: Test如果此处的Test.class在com.xx包下面，则需要指明。 如果在运行时报了invalid or corrupt jarfile错误，则需要检查Main-class: Test 之间是不是缺少了空格。 3.指定运行jar里面的class java -cp xx.jar com.xx.Test 4.编译某个java文件，但是依赖某个jar javac -cp xx.jar Test.java (Test.java里面import了xx.jar里面的某个class) 5.运行某个java文件，但是依赖某个jar java -cp .;xx.jar Test 注意：引用xx.jar的时候，不要漏掉.;（这个表示当前目录）","tags":[{"name":"java","slug":"java","permalink":"http://yzy755.github.io/tags/java/"},{"name":"jar包","slug":"jar包","permalink":"http://yzy755.github.io/tags/jar包/"}]},{"title":"微信小程序对接支付","date":"2017-03-02T09:17:53.000Z","path":"2017/03/02/redis使用不当/","text":"所有支付方式都需要通过 「统一下单」的 API 来获取一个支付凭证。但在小程序内测期间，还没有「统一下单」的概念。HTML 5 应用发起支付需要直接通过前端构造参数来发起（不经过后端验证），很容易造成支付凭证泄露等安全问题。为此，微信支付将其流程进行了优化：在所有支付场景中插入「统一下单」的特性。推荐开发者在后端完成支付参数的构建等行为。该优化带来以下好处: * 尽可能让开发者不犯低级错误，造成财务损失。 * 简化构造支付参数的复杂度，所有支付方式可共享一个支付后端接口。 通过「统一下单」获取到相对应 prepay_id 或者 code_url 等参数，即可通过各种支付模式的 SDK 来进行微信支付的发起。需要注意的是，必须对通知参数进行签名验证，以确保安全。进行签名验证时，除去签名字段（一般参数名为: sign）不需要参与签名外，其余所有接收到的参数均需要参与签名。比如拼接的请求支付宝的参数为total_fee,body,appid，那么签名就必须用这三个参数得到prepay_id后还需在发起wx.requestPayment前对 wx.requestPayment请求所需的参数进行签名所需的参数为’timeStamp’: res.data.timeStamp, ‘nonceStr’: nonce_str, ‘package’: ‘prepay_id=’+prepay_id, ‘signType’: ‘MD5’, ‘paySign’: res.data.sign,但是后台生成该签名还需appId（I大写！！）随后用返回的参数和生成的timeStamp进行请求（ appId、timeStamp、nonceStr、package、signType）。 之后又将微信支付集成到了web端，官方对于网页版的微信支付有两种模式，我使用的是更为简单的模式二，参考https://pay.weixin.qq.com/wiki/doc/api/native.php?chapter=6_5时序图如下：与小程序的统一下单api所需的参数不同的是：小程序的trade_type一定是”JSAPI”,相应的一定要传当前使用小程序的用户openid；扫码支付模式二的trade_type是”NATIVE”，不需要用户的openid,其他参数相同，为： wxRequestParam.setAppid(ConstantUtil.APP_ID); wxRequestParam.setMch_id(ConstantUtil.MCH_ID); wxRequestParam.setNonce_str(WXUtil.getNonceStr()); wxRequestParam.setBody(commonsOrder.getTitle()); wxRequestParam.setSpbill_create_ip(request.getRemoteAddr().startsWith(“0”)?”127.0.0.1”:request.getRemoteAddr()); wxRequestParam.setOut_trade_no(commonsOrder.getOrderCode()); wxRequestParam.setTotal_fee(StringUtils.substringBefore(String.valueOf(commonsOrder.getOrderFee().setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue() * 100), “.”)); wxRequestParam.setNotify_url(ConstantUtil.NOTIFY_URL); wxRequestParam.setSign(sign); wxRequestParam.setTrade_type(“NATIVE”); // 下面是小程序不同的参数 wxRequestParam.setOpenid(openid); wxRequestParam.setTrade_type(“JSAPI”); 统一下单后返回参数中有一个code_url，使用 http://qr.liantu.com/api.php?text=code_url 即可看到一张二维码，扫码就支付啦，是不是比较简单- - ——————————————–2017.4.6更新——————————————————老大说使用其他网站平台生成二维码感觉不靠谱，所以去网上看了下有没有自己“画”二维码的库类，当然是有的，google爸爸就有一套基于nio的图片制作工具：添加依赖： &lt;dependency&gt; &lt;groupId&gt;com.google.zxing&lt;/groupId&gt; &lt;artifactId&gt;core&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.zxing&lt;/groupId&gt; &lt;artifactId&gt;javase&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; 编写工具类，代码如下： /** * @param qrImagePath 生成的图片绝对路径 * @param qrImageName 生成的图片名称 * @param content 待扫描的内容 * @throws WriterException * @throws IOException */ public static String createQRcode(String qrImagePath, String qrImageName, String content) throws WriterException, IOException { int width = 300; // 图像宽度 int height = 300; // 图像高度 String format = &quot;png&quot;;// 图像类型 Map&lt;EncodeHintType, Object&gt; hints = new HashMap&lt;EncodeHintType, Object&gt;(); hints.put(EncodeHintType.CHARACTER_SET, &quot;UTF-8&quot;); BitMatrix bitMatrix = new MultiFormatWriter().encode(content, BarcodeFormat.QR_CODE, width, height, hints);// 生成矩阵 Path path = FileSystems.getDefault().getPath(qrImagePath, qrImageName); MatrixToImageWriter.writeToPath(bitMatrix, format, path);// 输出图像 return path.toString(); } // 原来的生成方法 public static String QRfromLiantu(String chl) throws Exception { chl = UrlEncode(chl); String QRfromLiantu = &quot;http://qr.liantu.com/api.php?text=&quot; + chl; return QRfromLiantu; } // 特殊字符处理 public static String UrlEncode(String src) throws UnsupportedEncodingException { return URLEncoder.encode(src, &quot;UTF-8&quot;).replace(&quot;+&quot;, &quot;%20&quot;); } 然后调用就简单啦，消除领导的顾虑看了下京东的微信二维码支付，一分钟刷新一次，有自己独立的二维码服务，后期抽空研究下。。。","tags":[{"name":"redis","slug":"redis","permalink":"http://yzy755.github.io/tags/redis/"}]},{"title":"solr分词 同义词 停止词","date":"2017-03-02T09:17:53.000Z","path":"2017/03/02/solr分词 同义词 停止词/","text":"分词相关拓展，配置博微软件中特有的分词和停止词：特有的分词指的是博微软件中的词组，比如“定额”、“土方”等停止词是无功能意义的词，比如is 、a 、are 、”的”，“得”，“我” 等，这些词会在句子中多次出现却无意义，所以在分词的时候需要把这些词过滤掉。使用IKAnalyzer中文分词器，在collection/conf/schema.xml中配置 &lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer class=&quot;org.wltea.analyzer.lucene.IKAnalyzer&quot;/&gt; &lt;analyzer&gt; &lt;tokenizer class=&quot;solr.WhitespaceTokenizerFactory&quot;/&gt; &lt;/analyzer&gt; 需要使用IKAnalyzer分词器的字段配置type为text_ik，比如： &lt;field name=&quot;doc_title&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot; termVectors=&quot;true&quot;/&gt; 接下来就在solr的部署目录 WEB-INF/classes中增加配置如下：IKAnalyzer.cfg.xml内容配置如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt; &lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=&quot;ext_dict&quot;&gt;bwwiki.dic;&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;stopword.dic;&lt;/entry&gt; &lt;/properties&gt; Ps:同义词拓展（暂未实际应用）：在collection/conf/schema.xml中配置： &lt;fieldType name=&quot;text_syn&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer type=&quot;query&quot;&gt; &lt;tokenizer class=&quot;org.wltea.analyzer.lucene.IKTokenizerFactory&quot; useSmart=&quot;false&quot;/&gt; &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt; &lt;/analyzer&gt; &lt;analyzer type=&quot;index&quot;&gt; &lt;tokenizer class=&quot;org.wltea.analyzer.lucene.IKTokenizerFactory&quot; useSmart=&quot;fasle&quot;/&gt; &lt;filter class=&quot;solr.SynonymFilterFactory&quot; synonyms=&quot;synonyms.txt&quot; ignoreCase=&quot;true&quot; expand=&quot;true&quot; /&gt; &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt; 同级目录会带有synonyms.txt文件，可添加同义词组，以“,”隔开，比如：分词的测试方式如图：选中text_ik类型，可将“定额“、“土方“分词显示出来，并去掉配置的停止词“和”同义词测试方式相同。","tags":[{"name":"solr","slug":"solr","permalink":"http://yzy755.github.io/tags/solr/"}]},{"title":"solr部署","date":"2017-03-02T09:17:53.000Z","path":"2017/03/02/solr部署/","text":"http://www.tuicool.com/articles/mueARf 参考 请下载tgz包而不是zip包，特此提醒！ 解压solr-5.1.0.zip到任意盘符，如图： 复制solr.war到tomcat的webapps目录下，如图操作： 启动tomcat,如图：然后修改webapps\\solr\\WEB-INF下的web.xml配置文件，如图： 配置solr_home目录路径，如图： 然后我们需要去C盘创建一个solr_home文件夹，这就是我们SOLR_HOME根目录啦，如图： 然后我们需要把E:\\solr-5.1.0\\server\\solr目录下的所有文件及文件夹全部复制到我们刚刚创建的solr_home目录下，如图： 然后我们需要把E:\\solr-5.1.0\\server\\lib\\ext目录下的所有jar包 copy到E:\\apache-tomcat-7.0.55\\webapps\\solr\\WEB-INF\\lib目录下(E:\\apache-tomcat-7.0.55是我的tomcat安装根目录，请对照你们自己的tomcat安装目录进行调整，你懂的)，如图： 然后复制 E:\\solr-5.1.0\\server\\resources目录下的log4j.properties配置文件到E:\\apache-tomcat-7.0.55\\webapps\\solr\\WEB-INF目录下，如图操作： 然后重启我们的tomcat,如图： 打开你的浏览器，地址栏输入 http://localhost:8080/solr ， 访问我们的Solr Web后台。如果你能看到这个界面，即表明Solr5部署成功了，如图： 然后你就可以通过Solr Web UI添加Core啦，不过添加Core之前，你需要在solr_home目录下创建core文件夹，如图：core目录下需要创建conf和data文件夹，你懂的， 《跟益达学Solr5之使用Jetty部署Solr》这篇博客也提到过，如图： 剩下的一些配置copy具体你们就参照那篇去操作把，这里就不重复说明了。到此，Solr5如何部署到Tomcat就讲解完毕了！ IK 分词器安装1.将之前解压的solr-4.3.1 下的contrib和dist 文件夹复制到F:\\winsolr\\solr_home\\solr\\collection1下2.将下载的IKAnalyzer的发行包解压，解压后将IKAnalyzer2012FF_u1.jar（分词器jar包）复制到F:\\winsolr\\solr_home\\solr\\collection1\\contrib\\analysis-extras\\lib下3.在F:\\winsolr\\apache-tomcat-7.0.37\\webapps\\solr\\WEB-INF下新建classes文件夹4.将IKAnalyzer解压出来的IKAnalyzer.cfg.xml（分词器配置文件）和 Stopword.dic（分词器停词字典,可自定义添加内容）复制到 F:\\winsolr\\apache-tomcat-7.0.37\\webapps\\solr\\WEB-INF\\classes中5.在F:\\winsolr\\solr_home\\solr\\collection1\\conf下的schema.xml文件中fieldType name=”text_general”这个地方的上方添加以下内容 将pinyinfj.jar、lucene-analyzers-smartcn-4.7.0.jar、IKAnalyzer2012FF_u1.jar、pinyinAnalyzer.jar、shentong_tsearch_lib.jar放到solr部署目录的web-inf的lib目录下","tags":[{"name":"solr","slug":"solr","permalink":"http://yzy755.github.io/tags/solr/"}]},{"title":"微信小程序对接支付","date":"2017-03-02T09:17:53.000Z","path":"2017/03/02/微信小程序对接支付/","text":"所有支付方式都需要通过 「统一下单」的 API 来获取一个支付凭证。但在小程序内测期间，还没有「统一下单」的概念。HTML 5 应用发起支付需要直接通过前端构造参数来发起（不经过后端验证），很容易造成支付凭证泄露等安全问题。为此，微信支付将其流程进行了优化：在所有支付场景中插入「统一下单」的特性。推荐开发者在后端完成支付参数的构建等行为。该优化带来以下好处: * 尽可能让开发者不犯低级错误，造成财务损失。 * 简化构造支付参数的复杂度，所有支付方式可共享一个支付后端接口。 通过「统一下单」获取到相对应 prepay_id 或者 code_url 等参数，即可通过各种支付模式的 SDK 来进行微信支付的发起。需要注意的是，必须对通知参数进行签名验证，以确保安全。进行签名验证时，除去签名字段（一般参数名为: sign）不需要参与签名外，其余所有接收到的参数均需要参与签名。比如拼接的请求支付宝的参数为total_fee,body,appid，那么签名就必须用这三个参数得到prepay_id后还需在发起wx.requestPayment前对 wx.requestPayment请求所需的参数进行签名所需的参数为’timeStamp’: res.data.timeStamp, ‘nonceStr’: nonce_str, ‘package’: ‘prepay_id=’+prepay_id, ‘signType’: ‘MD5’, ‘paySign’: res.data.sign,但是后台生成该签名还需appId（I大写！！）随后用返回的参数和生成的timeStamp进行请求（ appId、timeStamp、nonceStr、package、signType）。 之后又将微信支付集成到了web端，官方对于网页版的微信支付有两种模式，我使用的是更为简单的模式二，参考https://pay.weixin.qq.com/wiki/doc/api/native.php?chapter=6_5时序图如下：与小程序的统一下单api所需的参数不同的是：小程序的trade_type一定是”JSAPI”,相应的一定要传当前使用小程序的用户openid；扫码支付模式二的trade_type是”NATIVE”，不需要用户的openid,其他参数相同，为： wxRequestParam.setAppid(ConstantUtil.APP_ID); wxRequestParam.setMch_id(ConstantUtil.MCH_ID); wxRequestParam.setNonce_str(WXUtil.getNonceStr()); wxRequestParam.setBody(commonsOrder.getTitle()); wxRequestParam.setSpbill_create_ip(request.getRemoteAddr().startsWith(“0”)?”127.0.0.1”:request.getRemoteAddr()); wxRequestParam.setOut_trade_no(commonsOrder.getOrderCode()); wxRequestParam.setTotal_fee(StringUtils.substringBefore(String.valueOf(commonsOrder.getOrderFee().setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue() * 100), “.”)); wxRequestParam.setNotify_url(ConstantUtil.NOTIFY_URL); wxRequestParam.setSign(sign); wxRequestParam.setTrade_type(“NATIVE”); // 下面是小程序不同的参数 wxRequestParam.setOpenid(openid); wxRequestParam.setTrade_type(“JSAPI”); 统一下单后返回参数中有一个code_url，使用 http://qr.liantu.com/api.php?text=code_url 即可看到一张二维码，扫码就支付啦，是不是比较简单- - ——————————————–2017.4.6更新——————————————————老大说使用其他网站平台生成二维码感觉不靠谱，所以去网上看了下有没有自己“画”二维码的库类，当然是有的，google爸爸就有一套基于nio的图片制作工具：添加依赖： &lt;dependency&gt; &lt;groupId&gt;com.google.zxing&lt;/groupId&gt; &lt;artifactId&gt;core&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.zxing&lt;/groupId&gt; &lt;artifactId&gt;javase&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; 编写工具类，代码如下： /** * @param qrImagePath 生成的图片绝对路径 * @param qrImageName 生成的图片名称 * @param content 待扫描的内容 * @throws WriterException * @throws IOException */ public static String createQRcode(String qrImagePath, String qrImageName, String content) throws WriterException, IOException { int width = 300; // 图像宽度 int height = 300; // 图像高度 String format = &quot;png&quot;;// 图像类型 Map&lt;EncodeHintType, Object&gt; hints = new HashMap&lt;EncodeHintType, Object&gt;(); hints.put(EncodeHintType.CHARACTER_SET, &quot;UTF-8&quot;); BitMatrix bitMatrix = new MultiFormatWriter().encode(content, BarcodeFormat.QR_CODE, width, height, hints);// 生成矩阵 Path path = FileSystems.getDefault().getPath(qrImagePath, qrImageName); MatrixToImageWriter.writeToPath(bitMatrix, format, path);// 输出图像 return path.toString(); } // 原来的生成方法 public static String QRfromLiantu(String chl) throws Exception { chl = UrlEncode(chl); String QRfromLiantu = &quot;http://qr.liantu.com/api.php?text=&quot; + chl; return QRfromLiantu; } // 特殊字符处理 public static String UrlEncode(String src) throws UnsupportedEncodingException { return URLEncoder.encode(src, &quot;UTF-8&quot;).replace(&quot;+&quot;, &quot;%20&quot;); } 然后调用就简单啦，消除领导的顾虑看了下京东的微信二维码支付，一分钟刷新一次，有自己独立的二维码服务，后期抽空研究下。。。","tags":[{"name":"微信小程序","slug":"微信小程序","permalink":"http://yzy755.github.io/tags/微信小程序/"},{"name":"微信支付","slug":"微信支付","permalink":"http://yzy755.github.io/tags/微信支付/"}]}]